<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="org.hipi.examples.test.CovarTest" tests="7" skipped="0" failures="0" errors="0" timestamp="2015-08-12T17:38:36" hostname="Zacks-MacBook-Pro.local" time="235.192">
  <properties/>
  <testcase name="testComputeMeanInvalidNumberOfInputs" classname="org.hipi.examples.test.CovarTest" time="0.994"/>
  <testcase name="testComputeCovarianceInvalidNumberOfInputs" classname="org.hipi.examples.test.CovarTest" time="1.194"/>
  <testcase name="testComputeMeanInvalidInputPath" classname="org.hipi.examples.test.CovarTest" time="1.782"/>
  <testcase name="testComputeCovarianceInvalidInputPath" classname="org.hipi.examples.test.CovarTest" time="1.901"/>
  <testcase name="testComputeMean" classname="org.hipi.examples.test.CovarTest" time="7.795"/>
  <testcase name="testComputeCovarianceWithSmallTestHib" classname="org.hipi.examples.test.CovarTest" time="69.245"/>
  <testcase name="testComputeCovarianceWithMediumTestHib" classname="org.hipi.examples.test.CovarTest" time="152.277"/>
  <system-out><![CDATA[hadoop fs -rm -r -f /testout
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -rm -r -f /testout
Deleted /testout
</STDOUT>
<STDERR>
15/08/12 13:38:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 13:38:13 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
</STDERR>
EXITVAL: 0
hadoop fs -rm -r -f /tmp
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -rm -r -f /tmp
Deleted /tmp
</STDOUT>
<STDERR>
15/08/12 13:38:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 13:38:15 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p /testout
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /testout
</STDOUT>
<STDERR>
15/08/12 13:38:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p /tmp
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /tmp
</STDOUT>
<STDERR>
15/08/12 13:38:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p /testout/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /testout/covar
</STDOUT>
<STDERR>
15/08/12 13:38:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/white-black.hib /testout/covar/white-black.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/white-black.hib /testout/covar/white-black.hib
</STDOUT>
<STDERR>
15/08/12 13:38:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/white-black.hib.dat /testout/covar/white-black.hib.dat
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/white-black.hib.dat /testout/covar/white-black.hib.dat
</STDOUT>
<STDERR>
15/08/12 13:38:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib /testout/covar/smalltesthib.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib /testout/covar/smalltesthib.hib
</STDOUT>
<STDERR>
15/08/12 13:38:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib.dat /testout/covar/smalltesthib.hib.dat
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib.dat /testout/covar/smalltesthib.hib.dat
</STDOUT>
<STDERR>
15/08/12 13:38:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib /testout/covar/mediumtesthib.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib /testout/covar/mediumtesthib.hib
</STDOUT>
<STDERR>
15/08/12 13:38:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib.dat /testout/covar/mediumtesthib.hib.dat
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib.dat /testout/covar/mediumtesthib.hib.dat
</STDOUT>
<STDERR>
15/08/12 13:38:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/images/mean.jpg /testout/covar/mean.jpg
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/images/mean.jpg /testout/covar/mean.jpg
</STDOUT>
<STDERR>
15/08/12 13:38:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/images/covariance-benchmark.jpg /testout/covar/covariance-benchmark.jpg
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/images/covariance-benchmark.jpg /testout/covar/covariance-benchmark.jpg
</STDOUT>
<STDERR>
15/08/12 13:38:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeMean.sh onlyOneInput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar onlyOneInput
Running compute mean.
Usage: covariance <input HIB> <output directory>
</STDOUT>
<STDERR>
15/08/12 13:38:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeCovariance.sh onlyOneInput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar onlyOneInput
Running compute covariance.
Usage: covariance <input HIB> <output directory>
</STDOUT>
<STDERR>
15/08/12 13:38:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeMean.sh invalidInput invalidOutput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar invalidInput invalidOutput
Running compute mean.
Path to <input HIB> does not exist: invalidInput
</STDOUT>
<STDERR>
15/08/12 13:38:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeCovariance.sh invalidInput invalidOutput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar invalidInput invalidOutput
Running compute covariance.
Path to <input HIB> does not exist: invalidInput
</STDOUT>
<STDERR>
15/08/12 13:38:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeMean.sh /testout/covar/white-black.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/white-black.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 6791
</STDOUT>
<STDERR>
15/08/12 13:38:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 13:38:44 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 13:38:44 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 13:38:45 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 13:38:45 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 13:38:45 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 13:38:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local263376263_0001
15/08/12 13:38:45 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 13:38:45 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 13:38:45 INFO mapreduce.Job: Running job: job_local263376263_0001
15/08/12 13:38:45 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 13:38:45 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 13:38:45 INFO mapred.LocalJobRunner: Starting task: attempt_local263376263_0001_m_000000_0
15/08/12 13:38:45 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:38:45 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:38:45 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/white-black.hib.dat:0+6792
15/08/12 13:38:45 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 13:38:45 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 13:38:45 INFO mapred.MapTask: soft limit at 83886080
15/08/12 13:38:45 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 13:38:45 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 13:38:45 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 13:38:46 INFO mapreduce.Job: Job job_local263376263_0001 running in uber mode : false
15/08/12 13:38:46 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 13:38:46 INFO mapred.LocalJobRunner: 
15/08/12 13:38:46 INFO mapred.MapTask: Starting flush of map output
15/08/12 13:38:46 INFO mapred.MapTask: Spilling map output
15/08/12 13:38:46 INFO mapred.MapTask: bufstart = 0; bufend = 18464; bufvoid = 104857600
15/08/12 13:38:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
15/08/12 13:38:46 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 13:38:46 INFO mapred.MapTask: Finished spill 0
15/08/12 13:38:46 INFO mapred.Task: Task:attempt_local263376263_0001_m_000000_0 is done. And is in the process of committing
15/08/12 13:38:46 INFO mapred.LocalJobRunner: map
15/08/12 13:38:46 INFO mapred.Task: Task 'attempt_local263376263_0001_m_000000_0' done.
15/08/12 13:38:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local263376263_0001_m_000000_0
15/08/12 13:38:46 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 13:38:46 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 13:38:46 INFO mapred.LocalJobRunner: Starting task: attempt_local263376263_0001_r_000000_0
15/08/12 13:38:46 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:38:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:38:46 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@47e090f1
15/08/12 13:38:46 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 13:38:46 INFO reduce.EventFetcher: attempt_local263376263_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 13:38:46 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:38:46 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local263376263_0001_m_000000_0 decomp: 18474 len: 76 to MEMORY
15/08/12 13:38:46 INFO reduce.InMemoryMapOutput: Read 18474 bytes from map-output for attempt_local263376263_0001_m_000000_0
15/08/12 13:38:46 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18474, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18474
15/08/12 13:38:46 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 13:38:46 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:38:46 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 13:38:46 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:38:46 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18466 bytes
15/08/12 13:38:46 INFO reduce.MergeManagerImpl: Merged 1 segments, 18474 bytes to disk to satisfy reduce memory limit
15/08/12 13:38:46 INFO reduce.MergeManagerImpl: Merging 1 files, 84 bytes from disk
15/08/12 13:38:46 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 13:38:46 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:38:46 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18466 bytes
15/08/12 13:38:46 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:38:47 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 13:38:47 INFO mapred.Task: Task:attempt_local263376263_0001_r_000000_0 is done. And is in the process of committing
15/08/12 13:38:47 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:38:47 INFO mapred.Task: Task attempt_local263376263_0001_r_000000_0 is allowed to commit now
15/08/12 13:38:47 INFO output.FileOutputCommitter: Saved output of task 'attempt_local263376263_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local263376263_0001_r_000000
15/08/12 13:38:47 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 13:38:47 INFO mapred.Task: Task 'attempt_local263376263_0001_r_000000_0' done.
15/08/12 13:38:47 INFO mapred.LocalJobRunner: Finishing task: attempt_local263376263_0001_r_000000_0
15/08/12 13:38:47 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 13:38:47 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 13:38:47 INFO mapreduce.Job: Job job_local263376263_0001 completed successfully
15/08/12 13:38:47 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=37534
		FILE: Number of bytes written=564214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13664
		HDFS: Number of bytes written=9232
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=18464
		Map output materialized bytes=76
		Input split bytes=120
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=76
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=665845760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6792
	File Output Format Counters 
		Bytes Written=9232
</STDERR>
EXITVAL: 0
rm /tmp/mean-output-opencvmatwritable
<STDOUT>
</STDOUT>
<STDERR>
</STDERR>
EXITVAL: 0
hadoop fs -copyToLocal /tmp/covar/mean-output/part-r-00000 /tmp/mean-output-opencvmatwritable
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyToLocal /tmp/covar/mean-output/part-r-00000 /tmp/mean-output-opencvmatwritable
</STDOUT>
<STDERR>
15/08/12 13:38:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
compare -metric PSNR /tmp/mean-output.jpg ../../testdata/covar/images/mean.jpg /tmp/psnr.png
Images are identical (psnr == Float.MAX_VALUE)
PSNR: 3.4028235E38
./computeMean.sh /testout/covar/smalltesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/smalltesthib.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 14700465
</STDOUT>
<STDERR>
15/08/12 13:38:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 13:38:52 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 13:38:52 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 13:38:52 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 13:38:52 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 13:38:52 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 13:38:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1746800953_0001
15/08/12 13:38:52 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 13:38:52 INFO mapreduce.Job: Running job: job_local1746800953_0001
15/08/12 13:38:52 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 13:38:52 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 13:38:52 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 13:38:52 INFO mapred.LocalJobRunner: Starting task: attempt_local1746800953_0001_m_000000_0
15/08/12 13:38:52 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:38:52 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:38:52 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/smalltesthib.hib.dat:0+14700466
15/08/12 13:38:52 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 13:38:52 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 13:38:52 INFO mapred.MapTask: soft limit at 83886080
15/08/12 13:38:52 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 13:38:52 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 13:38:52 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 13:38:53 INFO mapreduce.Job: Job job_local1746800953_0001 running in uber mode : false
15/08/12 13:38:53 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 13:38:58 INFO mapred.LocalJobRunner: map > map
15/08/12 13:38:59 INFO mapreduce.Job:  map 42% reduce 0%
15/08/12 13:39:01 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:02 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:02 INFO mapred.MapTask: Starting flush of map output
15/08/12 13:39:02 INFO mapred.MapTask: Spilling map output
15/08/12 13:39:02 INFO mapred.MapTask: bufstart = 0; bufend = 64624; bufvoid = 104857600
15/08/12 13:39:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
15/08/12 13:39:02 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 13:39:02 INFO mapred.MapTask: Finished spill 0
15/08/12 13:39:02 INFO mapred.Task: Task:attempt_local1746800953_0001_m_000000_0 is done. And is in the process of committing
15/08/12 13:39:02 INFO mapred.LocalJobRunner: map
15/08/12 13:39:02 INFO mapred.Task: Task 'attempt_local1746800953_0001_m_000000_0' done.
15/08/12 13:39:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1746800953_0001_m_000000_0
15/08/12 13:39:02 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 13:39:02 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 13:39:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1746800953_0001_r_000000_0
15/08/12 13:39:02 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:39:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:39:02 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@66d3981f
15/08/12 13:39:02 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 13:39:02 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=364799584, maxSingleShuffleLimit=91199896, mergeThreshold=240767728, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 13:39:02 INFO reduce.EventFetcher: attempt_local1746800953_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 13:39:02 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:39:02 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1746800953_0001_m_000000_0 decomp: 64654 len: 49658 to MEMORY
15/08/12 13:39:02 INFO reduce.InMemoryMapOutput: Read 64654 bytes from map-output for attempt_local1746800953_0001_m_000000_0
15/08/12 13:39:02 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 64654, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->64654
15/08/12 13:39:02 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 13:39:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:39:02 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 13:39:02 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:39:02 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64646 bytes
15/08/12 13:39:02 INFO reduce.MergeManagerImpl: Merged 1 segments, 64654 bytes to disk to satisfy reduce memory limit
15/08/12 13:39:02 INFO reduce.MergeManagerImpl: Merging 1 files, 49666 bytes from disk
15/08/12 13:39:02 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 13:39:02 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:39:02 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64646 bytes
15/08/12 13:39:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:39:02 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 13:39:03 INFO mapred.Task: Task:attempt_local1746800953_0001_r_000000_0 is done. And is in the process of committing
15/08/12 13:39:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:39:03 INFO mapred.Task: Task attempt_local1746800953_0001_r_000000_0 is allowed to commit now
15/08/12 13:39:03 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1746800953_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local1746800953_0001_r_000000
15/08/12 13:39:03 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 13:39:03 INFO mapred.Task: Task 'attempt_local1746800953_0001_r_000000_0' done.
15/08/12 13:39:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1746800953_0001_r_000000_0
15/08/12 13:39:03 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 13:39:03 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 13:39:03 INFO mapreduce.Job: Job job_local1746800953_0001 completed successfully
15/08/12 13:39:03 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=136702
		FILE: Number of bytes written=715692
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29401092
		HDFS: Number of bytes written=9232
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=64624
		Map output materialized bytes=49658
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=49658
		Reduce input records=7
		Reduce output records=1
		Spilled Records=14
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=488
		Total committed heap usage (bytes)=1042284544
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14700466
	File Output Format Counters 
		Bytes Written=9232
</STDERR>
EXITVAL: 0
./computeCovariance.sh /testout/covar/smalltesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar /testout/covar/smalltesthib.hib /tmp/covar
Running compute covariance.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 14700465
</STDOUT>
<STDERR>
15/08/12 13:39:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 13:39:05 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
15/08/12 13:39:05 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 13:39:05 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 13:39:06 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 13:39:06 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 13:39:06 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 13:39:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1226801514_0001
15/08/12 13:39:06 INFO mapred.LocalDistributedCacheManager: Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439401146733/part-r-00000 <- /Users/zverham/Documents/School/4thYear/Research/hipi-covariance-update/hipi/examples/testSuite/part-r-00000
15/08/12 13:39:06 INFO mapred.LocalDistributedCacheManager: Localized hdfs://localhost:9000/tmp/covar/mean-output/part-r-00000 as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439401146733/part-r-00000
15/08/12 13:39:07 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 13:39:07 INFO mapreduce.Job: Running job: job_local1226801514_0001
15/08/12 13:39:07 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 13:39:07 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 13:39:07 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 13:39:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1226801514_0001_m_000000_0
15/08/12 13:39:07 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:39:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:39:07 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/smalltesthib.hib.dat:0+14700466
15/08/12 13:39:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 13:39:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 13:39:07 INFO mapred.MapTask: soft limit at 83886080
15/08/12 13:39:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 13:39:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 13:39:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 13:39:08 INFO mapreduce.Job: Job job_local1226801514_0001 running in uber mode : false
15/08/12 13:39:08 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 13:39:13 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:14 INFO mapreduce.Job:  map 31% reduce 0%
15/08/12 13:39:16 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:23 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:24 INFO mapreduce.Job:  map 56% reduce 0%
15/08/12 13:39:26 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:26 INFO mapred.MapTask: Spilling map output
15/08/12 13:39:26 INFO mapred.MapTask: bufstart = 0; bufend = 84934720; bufvoid = 104857600
15/08/12 13:39:26 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
15/08/12 13:39:26 INFO mapred.MapTask: (EQUATOR) 84934751 kvi 21233680(84934720)
15/08/12 13:39:26 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 13:39:27 INFO mapreduce.Job:  map 66% reduce 0%
15/08/12 13:39:29 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:31 INFO mapred.MapTask: Finished spill 0
15/08/12 13:39:31 INFO mapred.MapTask: (RESET) equator 84934751 kv 21233680(84934720) kvi 21233680(84934720)
15/08/12 13:39:33 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:35 INFO mapred.LocalJobRunner: map > map
15/08/12 13:39:35 INFO mapred.MapTask: Starting flush of map output
15/08/12 13:39:35 INFO mapred.MapTask: Spilling map output
15/08/12 13:39:35 INFO mapred.MapTask: bufstart = 84934751; bufend = 43778191; bufvoid = 104857600
15/08/12 13:39:35 INFO mapred.MapTask: kvstart = 21233680(84934720); kvend = 21233672(84934688); length = 9/6553600
15/08/12 13:39:36 INFO mapred.LocalJobRunner: map > sort
15/08/12 13:39:36 INFO mapreduce.Job:  map 67% reduce 0%
15/08/12 13:39:39 INFO mapred.LocalJobRunner: map > sort
15/08/12 13:39:39 INFO mapred.MapTask: Finished spill 1
15/08/12 13:39:39 INFO mapred.Merger: Merging 2 sorted segments
15/08/12 13:39:39 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:39:39 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:39:39 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 138771172 bytes
15/08/12 13:39:45 INFO mapred.LocalJobRunner: map > sort > 
15/08/12 13:39:45 INFO mapreduce.Job:  map 87% reduce 0%
15/08/12 13:39:50 INFO mapred.Task: Task:attempt_local1226801514_0001_m_000000_0 is done. And is in the process of committing
15/08/12 13:39:50 INFO mapred.LocalJobRunner: map > sort
15/08/12 13:39:50 INFO mapred.Task: Task 'attempt_local1226801514_0001_m_000000_0' done.
15/08/12 13:39:50 INFO mapred.LocalJobRunner: Finishing task: attempt_local1226801514_0001_m_000000_0
15/08/12 13:39:50 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 13:39:50 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 13:39:50 INFO mapred.LocalJobRunner: Starting task: attempt_local1226801514_0001_r_000000_0
15/08/12 13:39:50 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:39:50 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:39:50 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@523ae861
15/08/12 13:39:50 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=366634592, maxSingleShuffleLimit=91658648, mergeThreshold=241978848, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 13:39:50 INFO reduce.EventFetcher: attempt_local1226801514_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 13:39:50 INFO reduce.MergeManagerImpl: attempt_local1226801514_0001_m_000000_0: Shuffling to disk since 148635804 is greater than maxSingleShuffleLimit (91658648)
15/08/12 13:39:50 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1226801514_0001_m_000000_0 decomp: 148635804 len: 138770865 to DISK
15/08/12 13:39:51 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 13:39:52 INFO reduce.OnDiskMapOutput: Read 138770865 bytes from map-output for attempt_local1226801514_0001_m_000000_0
15/08/12 13:39:52 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 13:39:52 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:39:52 INFO reduce.MergeManagerImpl: finalMerge called with 0 in-memory map-outputs and 1 on-disk map-outputs
15/08/12 13:39:52 INFO reduce.MergeManagerImpl: Merging 1 files, 138770865 bytes from disk
15/08/12 13:39:52 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 13:39:52 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:39:52 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 148635794 bytes
15/08/12 13:39:52 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:39:52 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 13:39:53 INFO mapred.Task: Task:attempt_local1226801514_0001_r_000000_0 is done. And is in the process of committing
15/08/12 13:39:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:39:53 INFO mapred.Task: Task attempt_local1226801514_0001_r_000000_0 is allowed to commit now
15/08/12 13:39:53 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1226801514_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/covariance-output/_temporary/0/task_local1226801514_0001_r_000000
15/08/12 13:39:53 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 13:39:53 INFO mapred.Task: Task 'attempt_local1226801514_0001_r_000000_0' done.
15/08/12 13:39:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local1226801514_0001_r_000000_0
15/08/12 13:39:53 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 13:39:54 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 13:39:54 INFO mapreduce.Job: Job job_local1226801514_0001 completed successfully
15/08/12 13:39:54 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=555121492
		FILE: Number of bytes written=695528203
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29438012
		HDFS: Number of bytes written=21233680
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=148635760
		Map output materialized bytes=138770865
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=138770865
		Reduce input records=7
		Reduce output records=1
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=428
		Total committed heap usage (bytes)=1047527424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14700466
	File Output Format Counters 
		Bytes Written=21233680
</STDERR>
EXITVAL: 0
rm /tmp/covariance-output-opencvmatwritable
<STDOUT>
</STDOUT>
<STDERR>
</STDERR>
EXITVAL: 0
hadoop fs -copyToLocal /tmp/covar/covariance-output/part-r-00000 /tmp/covariance-output-opencvmatwritable
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyToLocal /tmp/covar/covariance-output/part-r-00000 /tmp/covariance-output-opencvmatwritable
</STDOUT>
<STDERR>
15/08/12 13:39:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
compare -metric PSNR /tmp/covariance-output.jpg ../../testdata/covar/images/covariance-benchmark.jpg /tmp/psnr.png
PSNR: 47.5601
./computeMean.sh /testout/covar/mediumtesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/mediumtesthib.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 348336
</STDOUT>
<STDERR>
15/08/12 13:40:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 13:40:01 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 13:40:01 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 13:40:01 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 13:40:01 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 13:40:01 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 13:40:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1078884506_0001
15/08/12 13:40:01 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 13:40:01 INFO mapreduce.Job: Running job: job_local1078884506_0001
15/08/12 13:40:01 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 13:40:01 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 13:40:01 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 13:40:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1078884506_0001_m_000000_0
15/08/12 13:40:02 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:40:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:40:02 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/mediumtesthib.hib.dat:0+348337
15/08/12 13:40:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 13:40:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 13:40:02 INFO mapred.MapTask: soft limit at 83886080
15/08/12 13:40:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 13:40:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 13:40:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 13:40:02 INFO mapreduce.Job: Job job_local1078884506_0001 running in uber mode : false
15/08/12 13:40:02 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 13:40:05 INFO mapred.LocalJobRunner: 
15/08/12 13:40:05 INFO mapred.MapTask: Starting flush of map output
15/08/12 13:40:05 INFO mapred.MapTask: Spilling map output
15/08/12 13:40:05 INFO mapred.MapTask: bufstart = 0; bufend = 230800; bufvoid = 104857600
15/08/12 13:40:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
15/08/12 13:40:05 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 13:40:05 INFO mapred.MapTask: Finished spill 0
15/08/12 13:40:05 INFO mapred.Task: Task:attempt_local1078884506_0001_m_000000_0 is done. And is in the process of committing
15/08/12 13:40:05 INFO mapred.LocalJobRunner: map
15/08/12 13:40:05 INFO mapred.Task: Task 'attempt_local1078884506_0001_m_000000_0' done.
15/08/12 13:40:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1078884506_0001_m_000000_0
15/08/12 13:40:05 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 13:40:05 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 13:40:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1078884506_0001_r_000000_0
15/08/12 13:40:05 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:40:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:40:05 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ff837e1
15/08/12 13:40:05 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 13:40:05 INFO reduce.EventFetcher: attempt_local1078884506_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 13:40:05 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:40:05 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1078884506_0001_m_000000_0 decomp: 230902 len: 185910 to MEMORY
15/08/12 13:40:05 INFO reduce.InMemoryMapOutput: Read 230902 bytes from map-output for attempt_local1078884506_0001_m_000000_0
15/08/12 13:40:05 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 230902, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->230902
15/08/12 13:40:05 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 13:40:05 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:40:05 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 13:40:05 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:40:05 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 230894 bytes
15/08/12 13:40:05 INFO reduce.MergeManagerImpl: Merged 1 segments, 230902 bytes to disk to satisfy reduce memory limit
15/08/12 13:40:05 INFO reduce.MergeManagerImpl: Merging 1 files, 185918 bytes from disk
15/08/12 13:40:05 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 13:40:05 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:40:05 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 230894 bytes
15/08/12 13:40:05 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:40:05 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 13:40:05 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 13:40:06 INFO mapred.Task: Task:attempt_local1078884506_0001_r_000000_0 is done. And is in the process of committing
15/08/12 13:40:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:40:06 INFO mapred.Task: Task attempt_local1078884506_0001_r_000000_0 is allowed to commit now
15/08/12 13:40:06 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1078884506_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local1078884506_0001_r_000000
15/08/12 13:40:06 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 13:40:06 INFO mapred.Task: Task 'attempt_local1078884506_0001_r_000000_0' done.
15/08/12 13:40:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1078884506_0001_r_000000_0
15/08/12 13:40:06 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 13:40:06 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 13:40:06 INFO mapreduce.Job: Job job_local1078884506_0001 completed successfully
15/08/12 13:40:06 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=409208
		FILE: Number of bytes written=1124454
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=697122
		HDFS: Number of bytes written=9232
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=230800
		Map output materialized bytes=185910
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=185910
		Reduce input records=25
		Reduce output records=1
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=161
		Total committed heap usage (bytes)=675807232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=348337
	File Output Format Counters 
		Bytes Written=9232
</STDERR>
EXITVAL: 0
./computeCovariance.sh /testout/covar/mediumtesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar /testout/covar/mediumtesthib.hib /tmp/covar
Running compute covariance.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 348336
</STDOUT>
<STDERR>
15/08/12 13:40:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 13:40:08 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
15/08/12 13:40:09 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 13:40:09 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 13:40:09 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 13:40:09 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 13:40:09 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 13:40:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local272395253_0001
15/08/12 13:40:09 INFO mapred.LocalDistributedCacheManager: Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439401209758/part-r-00000 <- /Users/zverham/Documents/School/4thYear/Research/hipi-covariance-update/hipi/examples/testSuite/part-r-00000
15/08/12 13:40:09 INFO mapred.LocalDistributedCacheManager: Localized hdfs://localhost:9000/tmp/covar/mean-output/part-r-00000 as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439401209758/part-r-00000
15/08/12 13:40:09 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 13:40:09 INFO mapreduce.Job: Running job: job_local272395253_0001
15/08/12 13:40:09 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 13:40:09 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 13:40:10 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 13:40:10 INFO mapred.LocalJobRunner: Starting task: attempt_local272395253_0001_m_000000_0
15/08/12 13:40:10 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:40:10 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:40:10 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/mediumtesthib.hib.dat:0+348337
15/08/12 13:40:10 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 13:40:10 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 13:40:10 INFO mapred.MapTask: soft limit at 83886080
15/08/12 13:40:10 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 13:40:10 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 13:40:10 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 13:40:10 INFO mapreduce.Job: Job job_local272395253_0001 running in uber mode : false
15/08/12 13:40:10 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 13:40:16 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:17 INFO mapreduce.Job:  map 8% reduce 0%
15/08/12 13:40:19 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:22 INFO mapreduce.Job:  map 11% reduce 0%
15/08/12 13:40:22 INFO mapred.MapTask: Spilling map output
15/08/12 13:40:22 INFO mapred.MapTask: bufstart = 0; bufend = 84934720; bufvoid = 104857600
15/08/12 13:40:22 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
15/08/12 13:40:22 INFO mapred.MapTask: (EQUATOR) 84934751 kvi 21233680(84934720)
15/08/12 13:40:22 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 13:40:22 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:23 INFO mapreduce.Job:  map 15% reduce 0%
15/08/12 13:40:25 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:26 INFO mapred.MapTask: Finished spill 0
15/08/12 13:40:26 INFO mapred.MapTask: (RESET) equator 84934751 kv 21233680(84934720) kvi 21233680(84934720)
15/08/12 13:40:31 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:32 INFO mapreduce.Job:  map 22% reduce 0%
15/08/12 13:40:34 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:35 INFO mapred.MapTask: Spilling map output
15/08/12 13:40:35 INFO mapred.MapTask: bufstart = 84934751; bufend = 65011871; bufvoid = 104857600
15/08/12 13:40:35 INFO mapred.MapTask: kvstart = 21233680(84934720); kvend = 21233668(84934672); length = 13/6553600
15/08/12 13:40:35 INFO mapred.MapTask: (EQUATOR) 65011902 kvi 16252968(65011872)
15/08/12 13:40:35 INFO mapreduce.Job:  map 26% reduce 0%
15/08/12 13:40:37 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:40 INFO mapred.MapTask: Finished spill 1
15/08/12 13:40:40 INFO mapred.MapTask: (RESET) equator 65011902 kv 16252968(65011872) kvi 16252968(65011872)
15/08/12 13:40:42 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:43 INFO mapreduce.Job:  map 28% reduce 0%
15/08/12 13:40:45 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:46 INFO mapreduce.Job:  map 34% reduce 0%
15/08/12 13:40:48 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:48 INFO mapred.MapTask: Spilling map output
15/08/12 13:40:48 INFO mapred.MapTask: bufstart = 65011902; bufend = 45089022; bufvoid = 104857600
15/08/12 13:40:48 INFO mapred.MapTask: kvstart = 16252968(65011872); kvend = 16252956(65011824); length = 13/6553600
15/08/12 13:40:48 INFO mapred.MapTask: (EQUATOR) 45089053 kvi 11272256(45089024)
15/08/12 13:40:49 INFO mapreduce.Job:  map 38% reduce 0%
15/08/12 13:40:51 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:54 INFO mapred.MapTask: Finished spill 2
15/08/12 13:40:54 INFO mapred.MapTask: (RESET) equator 45089053 kv 11272256(45089024) kvi 11272256(45089024)
15/08/12 13:40:54 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:56 INFO mapreduce.Job:  map 39% reduce 0%
15/08/12 13:40:57 INFO mapred.LocalJobRunner: map > map
15/08/12 13:40:58 INFO mapreduce.Job:  map 43% reduce 0%
15/08/12 13:41:00 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:03 INFO mapreduce.Job:  map 47% reduce 0%
15/08/12 13:41:03 INFO mapred.MapTask: Spilling map output
15/08/12 13:41:03 INFO mapred.MapTask: bufstart = 45089053; bufend = 25166173; bufvoid = 104857600
15/08/12 13:41:03 INFO mapred.MapTask: kvstart = 11272256(45089024); kvend = 11272244(45088976); length = 13/6553600
15/08/12 13:41:03 INFO mapred.MapTask: (EQUATOR) 25166204 kvi 6291544(25166176)
15/08/12 13:41:03 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:06 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:08 INFO mapred.MapTask: Finished spill 3
15/08/12 13:41:08 INFO mapred.MapTask: (RESET) equator 25166204 kv 6291544(25166176) kvi 6291544(25166176)
15/08/12 13:41:13 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:13 INFO mapreduce.Job:  map 54% reduce 0%
15/08/12 13:41:16 INFO mapred.MapTask: Spilling map output
15/08/12 13:41:16 INFO mapred.MapTask: bufstart = 25166204; bufend = 5243324; bufvoid = 104857600
15/08/12 13:41:16 INFO mapred.MapTask: kvstart = 6291544(25166176); kvend = 6291532(25166128); length = 13/6553600
15/08/12 13:41:16 INFO mapred.MapTask: (EQUATOR) 5243355 kvi 1310832(5243328)
15/08/12 13:41:16 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:16 INFO mapreduce.Job:  map 58% reduce 0%
15/08/12 13:41:19 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:21 INFO mapred.MapTask: Finished spill 4
15/08/12 13:41:21 INFO mapred.MapTask: (RESET) equator 5243355 kv 1310832(5243328) kvi 1310832(5243328)
15/08/12 13:41:27 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:28 INFO mapreduce.Job:  map 63% reduce 0%
15/08/12 13:41:29 INFO mapred.MapTask: Spilling map output
15/08/12 13:41:29 INFO mapred.MapTask: bufstart = 5243355; bufend = 90178075; bufvoid = 104857600
15/08/12 13:41:29 INFO mapred.MapTask: kvstart = 1310832(5243328); kvend = 1310820(5243280); length = 13/6553600
15/08/12 13:41:29 INFO mapred.MapTask: (EQUATOR) 90178106 kvi 22544520(90178080)
15/08/12 13:41:30 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:30 INFO mapreduce.Job:  map 67% reduce 0%
15/08/12 13:41:33 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:34 INFO mapred.MapTask: Finished spill 5
15/08/12 13:41:34 INFO mapred.MapTask: (RESET) equator 90178106 kv 22544520(90178080) kvi 22544520(90178080)
15/08/12 13:41:34 INFO mapred.LocalJobRunner: map > map
15/08/12 13:41:34 INFO mapred.MapTask: Starting flush of map output
15/08/12 13:41:34 INFO mapred.MapTask: Spilling map output
15/08/12 13:41:34 INFO mapred.MapTask: bufstart = 90178106; bufend = 6554186; bufvoid = 104857600
15/08/12 13:41:34 INFO mapred.MapTask: kvstart = 22544520(90178080); kvend = 22544520(90178080); length = 1/6553600
15/08/12 13:41:35 INFO mapred.MapTask: Finished spill 6
15/08/12 13:41:35 INFO mapred.Merger: Merging 7 sorted segments
15/08/12 13:41:35 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:41:35 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:41:35 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:41:35 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:41:35 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:41:35 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:41:35 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 13:41:35 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 496597007 bytes
15/08/12 13:41:39 INFO mapred.LocalJobRunner: map > sort > 
15/08/12 13:41:39 INFO mapreduce.Job:  map 71% reduce 0%
15/08/12 13:41:42 INFO mapred.LocalJobRunner: map > sort > 
15/08/12 13:41:42 INFO mapreduce.Job:  map 72% reduce 0%
15/08/12 13:42:14 INFO mapred.Task: Task:attempt_local272395253_0001_m_000000_0 is done. And is in the process of committing
15/08/12 13:42:14 INFO mapred.LocalJobRunner: map > sort
15/08/12 13:42:14 INFO mapred.Task: Task 'attempt_local272395253_0001_m_000000_0' done.
15/08/12 13:42:14 INFO mapred.LocalJobRunner: Finishing task: attempt_local272395253_0001_m_000000_0
15/08/12 13:42:14 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 13:42:14 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 13:42:14 INFO mapred.LocalJobRunner: Starting task: attempt_local272395253_0001_r_000000_0
15/08/12 13:42:14 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 13:42:14 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 13:42:14 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@354c33cf
15/08/12 13:42:14 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 13:42:14 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 13:42:14 INFO reduce.EventFetcher: attempt_local272395253_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 13:42:14 INFO reduce.MergeManagerImpl: attempt_local272395253_0001_m_000000_0: Shuffling to disk since 530842152 is greater than maxSingleShuffleLimit (83584616)
15/08/12 13:42:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local272395253_0001_m_000000_0 decomp: 530842152 len: 496596213 to DISK
15/08/12 13:42:20 INFO mapred.LocalJobRunner: reduce > copy
15/08/12 13:42:21 INFO reduce.OnDiskMapOutput: Read 496596213 bytes from map-output for attempt_local272395253_0001_m_000000_0
15/08/12 13:42:21 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 13:42:21 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:42:21 INFO reduce.MergeManagerImpl: finalMerge called with 0 in-memory map-outputs and 1 on-disk map-outputs
15/08/12 13:42:21 INFO reduce.MergeManagerImpl: Merging 1 files, 496596213 bytes from disk
15/08/12 13:42:21 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 13:42:21 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 13:42:21 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 530842142 bytes
15/08/12 13:42:21 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 13:42:21 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 13:42:23 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 13:42:23 INFO mapreduce.Job:  map 100% reduce 79%
15/08/12 13:42:26 INFO mapred.Task: Task:attempt_local272395253_0001_r_000000_0 is done. And is in the process of committing
15/08/12 13:42:26 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 13:42:26 INFO mapred.Task: Task attempt_local272395253_0001_r_000000_0 is allowed to commit now
15/08/12 13:42:26 INFO output.FileOutputCommitter: Saved output of task 'attempt_local272395253_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/covariance-output/_temporary/0/task_local272395253_0001_r_000000
15/08/12 13:42:26 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 13:42:26 INFO mapred.Task: Task 'attempt_local272395253_0001_r_000000_0' done.
15/08/12 13:42:26 INFO mapred.LocalJobRunner: Finishing task: attempt_local272395253_0001_r_000000_0
15/08/12 13:42:26 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 13:42:26 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 13:42:26 INFO mapreduce.Job: Job job_local272395253_0001 completed successfully
15/08/12 13:42:26 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=1986423960
		FILE: Number of bytes written=2487448803
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=734042
		HDFS: Number of bytes written=21233680
		HDFS: Number of read operations=61
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=530842000
		Map output materialized bytes=496596213
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=496596213
		Reduce input records=25
		Reduce output records=1
		Spilled Records=75
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=201
		Total committed heap usage (bytes)=978845696
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=348337
	File Output Format Counters 
		Bytes Written=21233680
</STDERR>
EXITVAL: 0
rm /tmp/covariance-output-opencvmatwritable
<STDOUT>
</STDOUT>
<STDERR>
</STDERR>
EXITVAL: 0
hadoop fs -copyToLocal /tmp/covar/covariance-output/part-r-00000 /tmp/covariance-output-opencvmatwritable
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyToLocal /tmp/covar/covariance-output/part-r-00000 /tmp/covariance-output-opencvmatwritable
</STDOUT>
<STDERR>
15/08/12 13:42:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
compare -metric PSNR /tmp/covariance-output.jpg ../../testdata/covar/images/covariance-benchmark.jpg /tmp/psnr.png
PSNR: 14.8925
]]></system-out>
  <system-err><![CDATA[log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
]]></system-err>
</testsuite>
