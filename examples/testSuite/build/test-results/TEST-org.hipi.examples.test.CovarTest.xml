<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="org.hipi.examples.test.CovarTest" tests="7" skipped="0" failures="3" errors="0" timestamp="2015-08-12T18:10:59" hostname="Zacks-MacBook-Pro.local" time="42.786">
  <properties/>
  <testcase name="testComputeMeanInvalidNumberOfInputs" classname="org.hipi.examples.test.CovarTest" time="1.199"/>
  <testcase name="testComputeCovarianceInvalidNumberOfInputs" classname="org.hipi.examples.test.CovarTest" time="1.1"/>
  <testcase name="testComputeMeanInvalidInputPath" classname="org.hipi.examples.test.CovarTest" time="1.688"/>
  <testcase name="testComputeCovarianceInvalidInputPath" classname="org.hipi.examples.test.CovarTest" time="1.719"/>
  <testcase name="testComputeMean" classname="org.hipi.examples.test.CovarTest" time="7.718">
    <failure message="java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create&#10;" type="java.lang.RuntimeException">java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.bytedeco.javacpp.opencv_core$Mat.allocate(Native Method)
	at org.bytedeco.javacpp.opencv_core$Mat.&lt;init&gt;(opencv_core.java:13840)
	at org.hipi.opencv.OpenCVMatWritable.readFields(OpenCVMatWritable.java:109)
	at org.hipi.examples.test.TestUtils.convertOpenCVMatWritableToJpg(TestUtils.java:73)
	at org.hipi.examples.test.CovarTest.testComputeMean(CovarTest.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
</failure>
  </testcase>
  <testcase name="testComputeCovarianceWithSmallTestHib" classname="org.hipi.examples.test.CovarTest" time="17.453">
    <failure message="java.lang.AssertionError: Failed to run covariance. Check setup. expected:&lt;0&gt; but was:&lt;1&gt;" type="java.lang.AssertionError">java.lang.AssertionError: Failed to run covariance. Check setup. expected:&lt;0&gt; but was:&lt;1&gt;
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.hipi.examples.test.CovarTest.testComputeCovarianceWithSmallTestHib(CovarTest.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
</failure>
  </testcase>
  <testcase name="testComputeCovarianceWithMediumTestHib" classname="org.hipi.examples.test.CovarTest" time="11.905">
    <failure message="java.lang.AssertionError: Failed to run covariance. Check setup. expected:&lt;0&gt; but was:&lt;1&gt;" type="java.lang.AssertionError">java.lang.AssertionError: Failed to run covariance. Check setup. expected:&lt;0&gt; but was:&lt;1&gt;
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.hipi.examples.test.CovarTest.testComputeCovarianceWithMediumTestHib(CovarTest.java:77)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
</failure>
  </testcase>
  <system-out><![CDATA[hadoop fs -rm -r -f /testout
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -rm -r -f /testout
Deleted /testout
</STDOUT>
<STDERR>
15/08/12 14:10:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:10:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
</STDERR>
EXITVAL: 0
hadoop fs -rm -r -f /tmp
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -rm -r -f /tmp
Deleted /tmp
</STDOUT>
<STDERR>
15/08/12 14:10:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:10:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p /testout
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /testout
</STDOUT>
<STDERR>
15/08/12 14:10:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p /tmp
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /tmp
</STDOUT>
<STDERR>
15/08/12 14:10:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p /testout/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /testout/covar
</STDOUT>
<STDERR>
15/08/12 14:10:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/white-black.hib /testout/covar/white-black.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/white-black.hib /testout/covar/white-black.hib
</STDOUT>
<STDERR>
15/08/12 14:10:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/white-black.hib.dat /testout/covar/white-black.hib.dat
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/white-black.hib.dat /testout/covar/white-black.hib.dat
</STDOUT>
<STDERR>
15/08/12 14:10:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib /testout/covar/smalltesthib.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib /testout/covar/smalltesthib.hib
</STDOUT>
<STDERR>
15/08/12 14:10:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib.dat /testout/covar/smalltesthib.hib.dat
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib.dat /testout/covar/smalltesthib.hib.dat
</STDOUT>
<STDERR>
15/08/12 14:10:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib /testout/covar/mediumtesthib.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib /testout/covar/mediumtesthib.hib
</STDOUT>
<STDERR>
15/08/12 14:10:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib.dat /testout/covar/mediumtesthib.hib.dat
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib.dat /testout/covar/mediumtesthib.hib.dat
</STDOUT>
<STDERR>
15/08/12 14:10:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/images/mean.jpg /testout/covar/mean.jpg
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/images/mean.jpg /testout/covar/mean.jpg
</STDOUT>
<STDERR>
15/08/12 14:10:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/images/covariance-benchmark.jpg /testout/covar/covariance-benchmark.jpg
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/images/covariance-benchmark.jpg /testout/covar/covariance-benchmark.jpg
</STDOUT>
<STDERR>
15/08/12 14:10:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeMean.sh onlyOneInput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar onlyOneInput
Running compute mean.
Usage: covariance <input HIB> <output directory>
</STDOUT>
<STDERR>
15/08/12 14:11:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeCovariance.sh onlyOneInput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar onlyOneInput
Running compute covariance.
Usage: covariance <input HIB> <output directory>
</STDOUT>
<STDERR>
15/08/12 14:11:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeMean.sh invalidInput invalidOutput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar invalidInput invalidOutput
Running compute mean.
Path to <input HIB> does not exist: invalidInput
</STDOUT>
<STDERR>
15/08/12 14:11:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeCovariance.sh invalidInput invalidOutput
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar invalidInput invalidOutput
Running compute covariance.
Path to <input HIB> does not exist: invalidInput
</STDOUT>
<STDERR>
15/08/12 14:11:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeMean.sh /testout/covar/white-black.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/white-black.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 6791
</STDOUT>
<STDERR>
15/08/12 14:11:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:06 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:06 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:07 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:07 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:07 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local202541579_0001
15/08/12 14:11:07 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:07 INFO mapreduce.Job: Running job: job_local202541579_0001
15/08/12 14:11:07 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:07 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:07 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:07 INFO mapred.LocalJobRunner: Starting task: attempt_local202541579_0001_m_000000_0
15/08/12 14:11:07 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:07 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/white-black.hib.dat:0+6792
15/08/12 14:11:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:07 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 14:11:08 INFO mapreduce.Job: Job job_local202541579_0001 running in uber mode : false
15/08/12 14:11:08 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:08 INFO mapred.LocalJobRunner: 
15/08/12 14:11:08 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:08 INFO mapred.MapTask: Spilling map output
15/08/12 14:11:08 INFO mapred.MapTask: bufstart = 0; bufend = 18464; bufvoid = 104857600
15/08/12 14:11:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
15/08/12 14:11:08 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:08 INFO mapred.MapTask: Finished spill 0
15/08/12 14:11:08 INFO mapred.Task: Task:attempt_local202541579_0001_m_000000_0 is done. And is in the process of committing
15/08/12 14:11:08 INFO mapred.LocalJobRunner: map
15/08/12 14:11:08 INFO mapred.Task: Task 'attempt_local202541579_0001_m_000000_0' done.
15/08/12 14:11:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local202541579_0001_m_000000_0
15/08/12 14:11:08 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:08 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 14:11:08 INFO mapred.LocalJobRunner: Starting task: attempt_local202541579_0001_r_000000_0
15/08/12 14:11:08 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:08 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fbb781
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 14:11:08 INFO reduce.EventFetcher: attempt_local202541579_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 14:11:08 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 14:11:08 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local202541579_0001_m_000000_0 decomp: 18474 len: 76 to MEMORY
15/08/12 14:11:08 INFO reduce.InMemoryMapOutput: Read 18474 bytes from map-output for attempt_local202541579_0001_m_000000_0
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18474, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18474
15/08/12 14:11:08 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 14:11:08 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 14:11:08 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:08 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18466 bytes
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: Merged 1 segments, 18474 bytes to disk to satisfy reduce memory limit
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: Merging 1 files, 84 bytes from disk
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 14:11:08 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:08 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18466 bytes
15/08/12 14:11:08 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:09 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 14:11:09 INFO mapred.Task: Task:attempt_local202541579_0001_r_000000_0 is done. And is in the process of committing
15/08/12 14:11:09 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:09 INFO mapred.Task: Task attempt_local202541579_0001_r_000000_0 is allowed to commit now
15/08/12 14:11:09 INFO output.FileOutputCommitter: Saved output of task 'attempt_local202541579_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local202541579_0001_r_000000
15/08/12 14:11:09 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 14:11:09 INFO mapred.Task: Task 'attempt_local202541579_0001_r_000000_0' done.
15/08/12 14:11:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local202541579_0001_r_000000_0
15/08/12 14:11:09 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 14:11:09 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 14:11:09 INFO mapreduce.Job: Job job_local202541579_0001 completed successfully
15/08/12 14:11:09 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=37402
		FILE: Number of bytes written=563130
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13664
		HDFS: Number of bytes written=45
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=18464
		Map output materialized bytes=76
		Input split bytes=120
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=76
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=672137216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6792
	File Output Format Counters 
		Bytes Written=45
</STDERR>
EXITVAL: 0
rm /tmp/mean-output-opencvmatwritable
<STDOUT>
</STDOUT>
<STDERR>
</STDERR>
EXITVAL: 0
hadoop fs -copyToLocal /tmp/covar/mean-output/part-r-00000 /tmp/mean-output-opencvmatwritable
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyToLocal /tmp/covar/mean-output/part-r-00000 /tmp/mean-output-opencvmatwritable
</STDOUT>
<STDERR>
15/08/12 14:11:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
./computeMean.sh /testout/covar/smalltesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/smalltesthib.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 14700465
</STDOUT>
<STDERR>
15/08/12 14:11:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:14 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:14 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:14 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:14 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:14 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1051500056_0001
15/08/12 14:11:14 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:14 INFO mapreduce.Job: Running job: job_local1051500056_0001
15/08/12 14:11:14 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:14 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:14 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:15 INFO mapred.LocalJobRunner: Starting task: attempt_local1051500056_0001_m_000000_0
15/08/12 14:11:15 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:15 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:15 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/smalltesthib.hib.dat:0+14700466
15/08/12 14:11:15 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:15 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:15 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:15 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:15 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:15 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 14:11:15 INFO mapreduce.Job: Job job_local1051500056_0001 running in uber mode : false
15/08/12 14:11:15 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:21 INFO mapred.LocalJobRunner: map > map
15/08/12 14:11:21 INFO mapreduce.Job:  map 42% reduce 0%
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map > map
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map > map
15/08/12 14:11:24 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:24 INFO mapred.MapTask: Spilling map output
15/08/12 14:11:24 INFO mapred.MapTask: bufstart = 0; bufend = 64624; bufvoid = 104857600
15/08/12 14:11:24 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
15/08/12 14:11:24 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:24 INFO mapred.MapTask: Finished spill 0
15/08/12 14:11:24 INFO mapred.Task: Task:attempt_local1051500056_0001_m_000000_0 is done. And is in the process of committing
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map
15/08/12 14:11:24 INFO mapred.Task: Task 'attempt_local1051500056_0001_m_000000_0' done.
15/08/12 14:11:24 INFO mapred.LocalJobRunner: Finishing task: attempt_local1051500056_0001_m_000000_0
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:24 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 14:11:24 INFO mapred.LocalJobRunner: Starting task: attempt_local1051500056_0001_r_000000_0
15/08/12 14:11:24 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:24 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:24 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6109e04e
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=364065568, maxSingleShuffleLimit=91016392, mergeThreshold=240283280, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 14:11:24 INFO reduce.EventFetcher: attempt_local1051500056_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 14:11:24 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 14:11:24 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1051500056_0001_m_000000_0 decomp: 64654 len: 49658 to MEMORY
15/08/12 14:11:24 INFO reduce.InMemoryMapOutput: Read 64654 bytes from map-output for attempt_local1051500056_0001_m_000000_0
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 64654, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->64654
15/08/12 14:11:24 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 14:11:24 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 14:11:24 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:24 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64646 bytes
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: Merged 1 segments, 64654 bytes to disk to satisfy reduce memory limit
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: Merging 1 files, 49666 bytes from disk
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 14:11:24 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:24 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64646 bytes
15/08/12 14:11:24 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:24 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 14:11:24 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 14:11:25 INFO mapred.Task: Task:attempt_local1051500056_0001_r_000000_0 is done. And is in the process of committing
15/08/12 14:11:25 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:25 INFO mapred.Task: Task attempt_local1051500056_0001_r_000000_0 is allowed to commit now
15/08/12 14:11:25 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1051500056_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local1051500056_0001_r_000000
15/08/12 14:11:25 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 14:11:25 INFO mapred.Task: Task 'attempt_local1051500056_0001_r_000000_0' done.
15/08/12 14:11:25 INFO mapred.LocalJobRunner: Finishing task: attempt_local1051500056_0001_r_000000_0
15/08/12 14:11:25 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 14:11:25 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 14:11:25 INFO mapreduce.Job: Job job_local1051500056_0001 completed successfully
15/08/12 14:11:26 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=136570
		FILE: Number of bytes written=714596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29401092
		HDFS: Number of bytes written=45
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=64624
		Map output materialized bytes=49658
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=49658
		Reduce input records=7
		Reduce output records=1
		Spilled Records=14
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=449
		Total committed heap usage (bytes)=1040187392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14700466
	File Output Format Counters 
		Bytes Written=45
</STDERR>
EXITVAL: 0
./computeCovariance.sh /testout/covar/smalltesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar /testout/covar/smalltesthib.hib /tmp/covar
Running compute covariance.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 14700465
</STDOUT>
<STDERR>
15/08/12 14:11:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:27 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
15/08/12 14:11:28 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:28 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:28 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:28 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:28 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1872133520_0001
15/08/12 14:11:28 INFO mapred.LocalDistributedCacheManager: Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403088649/part-r-00000 <- /Users/zverham/Documents/School/4thYear/Research/hipi-covariance-update/hipi/examples/testSuite/part-r-00000
15/08/12 14:11:28 INFO mapred.LocalDistributedCacheManager: Localized hdfs://localhost:9000/tmp/covar/mean-output/part-r-00000 as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403088649/part-r-00000
15/08/12 14:11:28 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:28 INFO mapreduce.Job: Running job: job_local1872133520_0001
15/08/12 14:11:28 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:28 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:28 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:28 INFO mapred.LocalJobRunner: Starting task: attempt_local1872133520_0001_m_000000_0
15/08/12 14:11:28 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:28 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:28 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/smalltesthib.hib.dat:0+14700466
15/08/12 14:11:29 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:29 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:29 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:29 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:29 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:29 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java(56781,0x1221fd000) malloc: *** mach_vm_map(size=973358629015654400) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCV Error: Insufficient memory (Failed to allocate 973358629015653878 bytes) in OutOfMemoryError, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/alloc.cpp, line 52
OpenCV Error: Assertion failed (u != 0) in create, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp, line 411
15/08/12 14:11:29 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:29 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:29 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:29 WARN mapred.LocalJobRunner: job_local1872133520_0001
java.lang.Exception: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.bytedeco.javacpp.opencv_core$Mat.allocate(Native Method)
	at org.bytedeco.javacpp.opencv_core$Mat.<init>(opencv_core.java:13840)
	at org.hipi.opencv.OpenCVMatWritable.readFields(OpenCVMatWritable.java:109)
	at org.hipi.examples.covar.CovarianceMapper.setup(CovarianceMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15/08/12 14:11:29 INFO mapreduce.Job: Job job_local1872133520_0001 running in uber mode : false
15/08/12 14:11:29 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:29 INFO mapreduce.Job: Job job_local1872133520_0001 failed with state FAILED due to: NA
15/08/12 14:11:29 INFO mapreduce.Job: Counters: 0
</STDERR>
EXITVAL: 1
./computeMean.sh /testout/covar/mediumtesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/mediumtesthib.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 348336
</STDOUT>
<STDERR>
15/08/12 14:11:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:31 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:31 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:32 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:32 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:32 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local858841263_0001
15/08/12 14:11:32 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:32 INFO mapreduce.Job: Running job: job_local858841263_0001
15/08/12 14:11:32 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:32 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:32 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:32 INFO mapred.LocalJobRunner: Starting task: attempt_local858841263_0001_m_000000_0
15/08/12 14:11:32 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:32 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/mediumtesthib.hib.dat:0+348337
15/08/12 14:11:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:32 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 14:11:33 INFO mapreduce.Job: Job job_local858841263_0001 running in uber mode : false
15/08/12 14:11:33 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 
15/08/12 14:11:36 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:36 INFO mapred.MapTask: Spilling map output
15/08/12 14:11:36 INFO mapred.MapTask: bufstart = 0; bufend = 230800; bufvoid = 104857600
15/08/12 14:11:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
15/08/12 14:11:36 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:36 INFO mapred.MapTask: Finished spill 0
15/08/12 14:11:36 INFO mapred.Task: Task:attempt_local858841263_0001_m_000000_0 is done. And is in the process of committing
15/08/12 14:11:36 INFO mapred.LocalJobRunner: map
15/08/12 14:11:36 INFO mapred.Task: Task 'attempt_local858841263_0001_m_000000_0' done.
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local858841263_0001_m_000000_0
15/08/12 14:11:36 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Starting task: attempt_local858841263_0001_r_000000_0
15/08/12 14:11:36 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:36 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ecb3be1
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 14:11:36 INFO reduce.EventFetcher: attempt_local858841263_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 14:11:36 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 14:11:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local858841263_0001_m_000000_0 decomp: 230902 len: 185910 to MEMORY
15/08/12 14:11:36 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 14:11:36 INFO reduce.InMemoryMapOutput: Read 230902 bytes from map-output for attempt_local858841263_0001_m_000000_0
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 230902, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->230902
15/08/12 14:11:36 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 14:11:36 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:36 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 230894 bytes
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: Merged 1 segments, 230902 bytes to disk to satisfy reduce memory limit
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: Merging 1 files, 185918 bytes from disk
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 14:11:36 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:36 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 230894 bytes
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:36 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 14:11:36 INFO mapred.Task: Task:attempt_local858841263_0001_r_000000_0 is done. And is in the process of committing
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:36 INFO mapred.Task: Task attempt_local858841263_0001_r_000000_0 is allowed to commit now
15/08/12 14:11:36 INFO output.FileOutputCommitter: Saved output of task 'attempt_local858841263_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local858841263_0001_r_000000
15/08/12 14:11:36 INFO mapred.LocalJobRunner: reduce > reduce
15/08/12 14:11:36 INFO mapred.Task: Task 'attempt_local858841263_0001_r_000000_0' done.
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local858841263_0001_r_000000_0
15/08/12 14:11:36 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 14:11:37 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 14:11:37 INFO mapreduce.Job: Job job_local858841263_0001 completed successfully
15/08/12 14:11:37 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=409076
		FILE: Number of bytes written=1120646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=697122
		HDFS: Number of bytes written=44
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=230800
		Map output materialized bytes=185910
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=185910
		Reduce input records=25
		Reduce output records=1
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=203
		Total committed heap usage (bytes)=861929472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=348337
	File Output Format Counters 
		Bytes Written=44
</STDERR>
EXITVAL: 0
./computeCovariance.sh /testout/covar/mediumtesthib.hib /tmp/covar
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar /testout/covar/mediumtesthib.hib /tmp/covar
Running compute covariance.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 348336
</STDOUT>
<STDERR>
15/08/12 14:11:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:39 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
15/08/12 14:11:39 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:39 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:40 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:40 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:40 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1054280259_0001
15/08/12 14:11:40 INFO mapred.LocalDistributedCacheManager: Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403100593/part-r-00000 <- /Users/zverham/Documents/School/4thYear/Research/hipi-covariance-update/hipi/examples/testSuite/part-r-00000
15/08/12 14:11:40 INFO mapred.LocalDistributedCacheManager: Localized hdfs://localhost:9000/tmp/covar/mean-output/part-r-00000 as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403100593/part-r-00000
15/08/12 14:11:40 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:40 INFO mapreduce.Job: Running job: job_local1054280259_0001
15/08/12 14:11:40 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:40 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:40 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1054280259_0001_m_000000_0
15/08/12 14:11:40 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:40 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/mediumtesthib.hib.dat:0+348337
15/08/12 14:11:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:40 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java(56850,0x119687000) malloc: *** mach_vm_map(size=973358629015654400) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCV Error: Insufficient memory (Failed to allocate 973358629015653878 bytes) in OutOfMemoryError, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/alloc.cpp, line 52
OpenCV Error: Assertion failed (u != 0) in create, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp, line 411
15/08/12 14:11:41 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:41 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:41 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:41 WARN mapred.LocalJobRunner: job_local1054280259_0001
java.lang.Exception: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.bytedeco.javacpp.opencv_core$Mat.allocate(Native Method)
	at org.bytedeco.javacpp.opencv_core$Mat.<init>(opencv_core.java:13840)
	at org.hipi.opencv.OpenCVMatWritable.readFields(OpenCVMatWritable.java:109)
	at org.hipi.examples.covar.CovarianceMapper.setup(CovarianceMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15/08/12 14:11:41 INFO mapreduce.Job: Job job_local1054280259_0001 running in uber mode : false
15/08/12 14:11:41 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:41 INFO mapreduce.Job: Job job_local1054280259_0001 failed with state FAILED due to: NA
15/08/12 14:11:41 INFO mapreduce.Job: Counters: 0
</STDERR>
EXITVAL: 1
]]></system-out>
  <system-err><![CDATA[log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
]]></system-err>
</testsuite>
