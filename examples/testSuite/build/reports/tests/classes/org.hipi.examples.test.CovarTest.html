<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=edge"/>
<title>Test results - Class org.hipi.examples.test.CovarTest</title>
<link href="../css/base-style.css" rel="stylesheet" type="text/css"/>
<link href="../css/style.css" rel="stylesheet" type="text/css"/>
<script src="../js/report.js" type="text/javascript"></script>
</head>
<body>
<div id="content">
<h1>Class org.hipi.examples.test.CovarTest</h1>
<div class="breadcrumbs">
<a href="../index.html">all</a> &gt; 
<a href="../packages/org.hipi.examples.test.html">org.hipi.examples.test</a> &gt; CovarTest</div>
<div id="summary">
<table>
<tr>
<td>
<div class="summaryGroup">
<table>
<tr>
<td>
<div class="infoBox" id="tests">
<div class="counter">7</div>
<p>tests</p>
</div>
</td>
<td>
<div class="infoBox" id="failures">
<div class="counter">3</div>
<p>failures</p>
</div>
</td>
<td>
<div class="infoBox" id="ignored">
<div class="counter">0</div>
<p>ignored</p>
</div>
</td>
<td>
<div class="infoBox" id="duration">
<div class="counter">42.782s</div>
<p>duration</p>
</div>
</td>
</tr>
</table>
</div>
</td>
<td>
<div class="infoBox failures" id="successRate">
<div class="percent">57%</div>
<p>successful</p>
</div>
</td>
</tr>
</table>
</div>
<div id="tabs">
<ul class="tabLinks">
<li>
<a href="#tab0">Failed tests</a>
</li>
<li>
<a href="#tab1">Tests</a>
</li>
<li>
<a href="#tab2">Standard output</a>
</li>
<li>
<a href="#tab3">Standard error</a>
</li>
</ul>
<div id="tab0" class="tab">
<h2>Failed tests</h2>
<div class="test">
<a name="testComputeCovarianceWithMediumTestHib"></a>
<h3 class="failures">testComputeCovarianceWithMediumTestHib</h3>
<span class="code">
<pre>java.lang.AssertionError: Failed to run covariance. Check setup. expected:&lt;0&gt; but was:&lt;1&gt;
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.hipi.examples.test.CovarTest.testComputeCovarianceWithMediumTestHib(CovarTest.java:77)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
</pre>
</span>
</div>
<div class="test">
<a name="testComputeCovarianceWithSmallTestHib"></a>
<h3 class="failures">testComputeCovarianceWithSmallTestHib</h3>
<span class="code">
<pre>java.lang.AssertionError: Failed to run covariance. Check setup. expected:&lt;0&gt; but was:&lt;1&gt;
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:472)
	at org.hipi.examples.test.CovarTest.testComputeCovarianceWithSmallTestHib(CovarTest.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
</pre>
</span>
</div>
<div class="test">
<a name="testComputeMean"></a>
<h3 class="failures">testComputeMean</h3>
<span class="code">
<pre>java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.bytedeco.javacpp.opencv_core$Mat.allocate(Native Method)
	at org.bytedeco.javacpp.opencv_core$Mat.&lt;init&gt;(opencv_core.java:13840)
	at org.hipi.opencv.OpenCVMatWritable.readFields(OpenCVMatWritable.java:109)
	at org.hipi.examples.test.TestUtils.convertOpenCVMatWritableToJpg(TestUtils.java:73)
	at org.hipi.examples.test.CovarTest.testComputeMean(CovarTest.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
</pre>
</span>
</div>
</div>
<div id="tab1" class="tab">
<h2>Tests</h2>
<table>
<thead>
<tr>
<th>Test</th>
<th>Duration</th>
<th>Result</th>
</tr>
</thead>
<tr>
<td class="success">testComputeCovarianceInvalidInputPath</td>
<td>1.719s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testComputeCovarianceInvalidNumberOfInputs</td>
<td>1.100s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="failures">testComputeCovarianceWithMediumTestHib</td>
<td>11.905s</td>
<td class="failures">failed</td>
</tr>
<tr>
<td class="failures">testComputeCovarianceWithSmallTestHib</td>
<td>17.453s</td>
<td class="failures">failed</td>
</tr>
<tr>
<td class="failures">testComputeMean</td>
<td>7.718s</td>
<td class="failures">failed</td>
</tr>
<tr>
<td class="success">testComputeMeanInvalidInputPath</td>
<td>1.688s</td>
<td class="success">passed</td>
</tr>
<tr>
<td class="success">testComputeMeanInvalidNumberOfInputs</td>
<td>1.199s</td>
<td class="success">passed</td>
</tr>
</table>
</div>
<div id="tab2" class="tab">
<h2>Standard output</h2>
<span class="code">
<pre>hadoop fs -rm -r -f /testout
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -rm -r -f /testout
Deleted /testout
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:10:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -rm -r -f /tmp
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -rm -r -f /tmp
Deleted /tmp
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:10:38 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -mkdir -p /testout
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /testout
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -mkdir -p /tmp
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /tmp
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -mkdir -p /testout/covar
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p /testout/covar
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/white-black.hib /testout/covar/white-black.hib
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/white-black.hib /testout/covar/white-black.hib
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/white-black.hib.dat /testout/covar/white-black.hib.dat
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/white-black.hib.dat /testout/covar/white-black.hib.dat
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib /testout/covar/smalltesthib.hib
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib /testout/covar/smalltesthib.hib
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib.dat /testout/covar/smalltesthib.hib.dat
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/smalltesthib.hib.dat /testout/covar/smalltesthib.hib.dat
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib /testout/covar/mediumtesthib.hib
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib /testout/covar/mediumtesthib.hib
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib.dat /testout/covar/mediumtesthib.hib.dat
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/hibs/mediumtesthib.hib.dat /testout/covar/mediumtesthib.hib.dat
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/images/mean.jpg /testout/covar/mean.jpg
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/images/mean.jpg /testout/covar/mean.jpg
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/covar/images/covariance-benchmark.jpg /testout/covar/covariance-benchmark.jpg
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/covar/images/covariance-benchmark.jpg /testout/covar/covariance-benchmark.jpg
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:10:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
./computeMean.sh onlyOneInput
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar onlyOneInput
Running compute mean.
Usage: covariance &lt;input HIB&gt; &lt;output directory&gt;
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
./computeCovariance.sh onlyOneInput
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar onlyOneInput
Running compute covariance.
Usage: covariance &lt;input HIB&gt; &lt;output directory&gt;
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
./computeMean.sh invalidInput invalidOutput
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar invalidInput invalidOutput
Running compute mean.
Path to &lt;input HIB&gt; does not exist: invalidInput
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
./computeCovariance.sh invalidInput invalidOutput
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar invalidInput invalidOutput
Running compute covariance.
Path to &lt;input HIB&gt; does not exist: invalidInput
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
./computeMean.sh /testout/covar/white-black.hib /tmp/covar
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/white-black.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 6791
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:06 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:06 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:07 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:07 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:07 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local202541579_0001
15/08/12 14:11:07 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:07 INFO mapreduce.Job: Running job: job_local202541579_0001
15/08/12 14:11:07 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:07 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:07 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:07 INFO mapred.LocalJobRunner: Starting task: attempt_local202541579_0001_m_000000_0
15/08/12 14:11:07 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:07 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/white-black.hib.dat:0+6792
15/08/12 14:11:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:07 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 14:11:08 INFO mapreduce.Job: Job job_local202541579_0001 running in uber mode : false
15/08/12 14:11:08 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:08 INFO mapred.LocalJobRunner: 
15/08/12 14:11:08 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:08 INFO mapred.MapTask: Spilling map output
15/08/12 14:11:08 INFO mapred.MapTask: bufstart = 0; bufend = 18464; bufvoid = 104857600
15/08/12 14:11:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
15/08/12 14:11:08 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:08 INFO mapred.MapTask: Finished spill 0
15/08/12 14:11:08 INFO mapred.Task: Task:attempt_local202541579_0001_m_000000_0 is done. And is in the process of committing
15/08/12 14:11:08 INFO mapred.LocalJobRunner: map
15/08/12 14:11:08 INFO mapred.Task: Task 'attempt_local202541579_0001_m_000000_0' done.
15/08/12 14:11:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local202541579_0001_m_000000_0
15/08/12 14:11:08 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:08 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 14:11:08 INFO mapred.LocalJobRunner: Starting task: attempt_local202541579_0001_r_000000_0
15/08/12 14:11:08 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:08 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fbb781
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 14:11:08 INFO reduce.EventFetcher: attempt_local202541579_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 14:11:08 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 14:11:08 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local202541579_0001_m_000000_0 decomp: 18474 len: 76 to MEMORY
15/08/12 14:11:08 INFO reduce.InMemoryMapOutput: Read 18474 bytes from map-output for attempt_local202541579_0001_m_000000_0
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 18474, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;18474
15/08/12 14:11:08 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 14:11:08 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 14:11:08 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:08 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18466 bytes
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: Merged 1 segments, 18474 bytes to disk to satisfy reduce memory limit
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: Merging 1 files, 84 bytes from disk
15/08/12 14:11:08 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 14:11:08 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:08 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18466 bytes
15/08/12 14:11:08 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:09 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 14:11:09 INFO mapred.Task: Task:attempt_local202541579_0001_r_000000_0 is done. And is in the process of committing
15/08/12 14:11:09 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:09 INFO mapred.Task: Task attempt_local202541579_0001_r_000000_0 is allowed to commit now
15/08/12 14:11:09 INFO output.FileOutputCommitter: Saved output of task 'attempt_local202541579_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local202541579_0001_r_000000
15/08/12 14:11:09 INFO mapred.LocalJobRunner: reduce &gt; reduce
15/08/12 14:11:09 INFO mapred.Task: Task 'attempt_local202541579_0001_r_000000_0' done.
15/08/12 14:11:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local202541579_0001_r_000000_0
15/08/12 14:11:09 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 14:11:09 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 14:11:09 INFO mapreduce.Job: Job job_local202541579_0001 completed successfully
15/08/12 14:11:09 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=37402
		FILE: Number of bytes written=563130
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13664
		HDFS: Number of bytes written=45
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=18464
		Map output materialized bytes=76
		Input split bytes=120
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=76
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=672137216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6792
	File Output Format Counters 
		Bytes Written=45
&lt;/STDERR&gt;
EXITVAL: 0
rm /tmp/mean-output-opencvmatwritable
&lt;STDOUT&gt;
&lt;/STDOUT&gt;
&lt;STDERR&gt;
&lt;/STDERR&gt;
EXITVAL: 0
hadoop fs -copyToLocal /tmp/covar/mean-output/part-r-00000 /tmp/mean-output-opencvmatwritable
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyToLocal /tmp/covar/mean-output/part-r-00000 /tmp/mean-output-opencvmatwritable
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
&lt;/STDERR&gt;
EXITVAL: 0
./computeMean.sh /testout/covar/smalltesthib.hib /tmp/covar
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/smalltesthib.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 14700465
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:14 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:14 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:14 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:14 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:14 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1051500056_0001
15/08/12 14:11:14 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:14 INFO mapreduce.Job: Running job: job_local1051500056_0001
15/08/12 14:11:14 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:14 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:14 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:15 INFO mapred.LocalJobRunner: Starting task: attempt_local1051500056_0001_m_000000_0
15/08/12 14:11:15 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:15 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:15 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/smalltesthib.hib.dat:0+14700466
15/08/12 14:11:15 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:15 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:15 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:15 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:15 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:15 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 14:11:15 INFO mapreduce.Job: Job job_local1051500056_0001 running in uber mode : false
15/08/12 14:11:15 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:21 INFO mapred.LocalJobRunner: map &gt; map
15/08/12 14:11:21 INFO mapreduce.Job:  map 42% reduce 0%
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map &gt; map
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map &gt; map
15/08/12 14:11:24 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:24 INFO mapred.MapTask: Spilling map output
15/08/12 14:11:24 INFO mapred.MapTask: bufstart = 0; bufend = 64624; bufvoid = 104857600
15/08/12 14:11:24 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
15/08/12 14:11:24 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:24 INFO mapred.MapTask: Finished spill 0
15/08/12 14:11:24 INFO mapred.Task: Task:attempt_local1051500056_0001_m_000000_0 is done. And is in the process of committing
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map
15/08/12 14:11:24 INFO mapred.Task: Task 'attempt_local1051500056_0001_m_000000_0' done.
15/08/12 14:11:24 INFO mapred.LocalJobRunner: Finishing task: attempt_local1051500056_0001_m_000000_0
15/08/12 14:11:24 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:24 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 14:11:24 INFO mapred.LocalJobRunner: Starting task: attempt_local1051500056_0001_r_000000_0
15/08/12 14:11:24 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:24 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:24 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6109e04e
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=364065568, maxSingleShuffleLimit=91016392, mergeThreshold=240283280, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 14:11:24 INFO reduce.EventFetcher: attempt_local1051500056_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 14:11:24 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 14:11:24 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1051500056_0001_m_000000_0 decomp: 64654 len: 49658 to MEMORY
15/08/12 14:11:24 INFO reduce.InMemoryMapOutput: Read 64654 bytes from map-output for attempt_local1051500056_0001_m_000000_0
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 64654, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;64654
15/08/12 14:11:24 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 14:11:24 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 14:11:24 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:24 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64646 bytes
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: Merged 1 segments, 64654 bytes to disk to satisfy reduce memory limit
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: Merging 1 files, 49666 bytes from disk
15/08/12 14:11:24 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 14:11:24 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:24 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64646 bytes
15/08/12 14:11:24 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:24 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 14:11:24 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 14:11:25 INFO mapred.Task: Task:attempt_local1051500056_0001_r_000000_0 is done. And is in the process of committing
15/08/12 14:11:25 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:25 INFO mapred.Task: Task attempt_local1051500056_0001_r_000000_0 is allowed to commit now
15/08/12 14:11:25 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1051500056_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local1051500056_0001_r_000000
15/08/12 14:11:25 INFO mapred.LocalJobRunner: reduce &gt; reduce
15/08/12 14:11:25 INFO mapred.Task: Task 'attempt_local1051500056_0001_r_000000_0' done.
15/08/12 14:11:25 INFO mapred.LocalJobRunner: Finishing task: attempt_local1051500056_0001_r_000000_0
15/08/12 14:11:25 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 14:11:25 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 14:11:25 INFO mapreduce.Job: Job job_local1051500056_0001 completed successfully
15/08/12 14:11:26 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=136570
		FILE: Number of bytes written=714596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29401092
		HDFS: Number of bytes written=45
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=64624
		Map output materialized bytes=49658
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=49658
		Reduce input records=7
		Reduce output records=1
		Spilled Records=14
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=449
		Total committed heap usage (bytes)=1040187392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14700466
	File Output Format Counters 
		Bytes Written=45
&lt;/STDERR&gt;
EXITVAL: 0
./computeCovariance.sh /testout/covar/smalltesthib.hib /tmp/covar
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar /testout/covar/smalltesthib.hib /tmp/covar
Running compute covariance.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 14700465
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:27 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
15/08/12 14:11:28 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:28 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:28 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:28 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:28 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1872133520_0001
15/08/12 14:11:28 INFO mapred.LocalDistributedCacheManager: Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403088649/part-r-00000 &lt;- /Users/zverham/Documents/School/4thYear/Research/hipi-covariance-update/hipi/examples/testSuite/part-r-00000
15/08/12 14:11:28 INFO mapred.LocalDistributedCacheManager: Localized hdfs://localhost:9000/tmp/covar/mean-output/part-r-00000 as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403088649/part-r-00000
15/08/12 14:11:28 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:28 INFO mapreduce.Job: Running job: job_local1872133520_0001
15/08/12 14:11:28 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:28 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:28 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:28 INFO mapred.LocalJobRunner: Starting task: attempt_local1872133520_0001_m_000000_0
15/08/12 14:11:28 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:28 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:28 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/smalltesthib.hib.dat:0+14700466
15/08/12 14:11:29 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:29 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:29 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:29 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:29 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:29 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java(56781,0x1221fd000) malloc: *** mach_vm_map(size=973358629015654400) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCV Error: Insufficient memory (Failed to allocate 973358629015653878 bytes) in OutOfMemoryError, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/alloc.cpp, line 52
OpenCV Error: Assertion failed (u != 0) in create, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp, line 411
15/08/12 14:11:29 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:29 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:29 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:29 WARN mapred.LocalJobRunner: job_local1872133520_0001
java.lang.Exception: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.bytedeco.javacpp.opencv_core$Mat.allocate(Native Method)
	at org.bytedeco.javacpp.opencv_core$Mat.&lt;init&gt;(opencv_core.java:13840)
	at org.hipi.opencv.OpenCVMatWritable.readFields(OpenCVMatWritable.java:109)
	at org.hipi.examples.covar.CovarianceMapper.setup(CovarianceMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15/08/12 14:11:29 INFO mapreduce.Job: Job job_local1872133520_0001 running in uber mode : false
15/08/12 14:11:29 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:29 INFO mapreduce.Job: Job job_local1872133520_0001 failed with state FAILED due to: NA
15/08/12 14:11:29 INFO mapreduce.Job: Counters: 0
&lt;/STDERR&gt;
EXITVAL: 1
./computeMean.sh /testout/covar/mediumtesthib.hib /tmp/covar
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeMeanTestDriver.jar /testout/covar/mediumtesthib.hib /tmp/covar
Running compute mean.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 348336
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:31 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:31 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:32 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:32 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:32 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local858841263_0001
15/08/12 14:11:32 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:32 INFO mapreduce.Job: Running job: job_local858841263_0001
15/08/12 14:11:32 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:32 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:32 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:32 INFO mapred.LocalJobRunner: Starting task: attempt_local858841263_0001_m_000000_0
15/08/12 14:11:32 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:32 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/mediumtesthib.hib.dat:0+348337
15/08/12 14:11:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:32 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/12 14:11:33 INFO mapreduce.Job: Job job_local858841263_0001 running in uber mode : false
15/08/12 14:11:33 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 
15/08/12 14:11:36 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:36 INFO mapred.MapTask: Spilling map output
15/08/12 14:11:36 INFO mapred.MapTask: bufstart = 0; bufend = 230800; bufvoid = 104857600
15/08/12 14:11:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
15/08/12 14:11:36 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:36 INFO mapred.MapTask: Finished spill 0
15/08/12 14:11:36 INFO mapred.Task: Task:attempt_local858841263_0001_m_000000_0 is done. And is in the process of committing
15/08/12 14:11:36 INFO mapred.LocalJobRunner: map
15/08/12 14:11:36 INFO mapred.Task: Task 'attempt_local858841263_0001_m_000000_0' done.
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local858841263_0001_m_000000_0
15/08/12 14:11:36 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Starting task: attempt_local858841263_0001_r_000000_0
15/08/12 14:11:36 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:36 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ecb3be1
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/12 14:11:36 INFO reduce.EventFetcher: attempt_local858841263_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/12 14:11:36 INFO compress.CodecPool: Got brand-new decompressor [.deflate]
15/08/12 14:11:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local858841263_0001_m_000000_0 decomp: 230902 len: 185910 to MEMORY
15/08/12 14:11:36 INFO mapreduce.Job:  map 100% reduce 0%
15/08/12 14:11:36 INFO reduce.InMemoryMapOutput: Read 230902 bytes from map-output for attempt_local858841263_0001_m_000000_0
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 230902, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;230902
15/08/12 14:11:36 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/12 14:11:36 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:36 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 230894 bytes
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: Merged 1 segments, 230902 bytes to disk to satisfy reduce memory limit
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: Merging 1 files, 185918 bytes from disk
15/08/12 14:11:36 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/12 14:11:36 INFO mapred.Merger: Merging 1 sorted segments
15/08/12 14:11:36 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 230894 bytes
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:36 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/12 14:11:36 INFO mapred.Task: Task:attempt_local858841263_0001_r_000000_0 is done. And is in the process of committing
15/08/12 14:11:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/12 14:11:36 INFO mapred.Task: Task attempt_local858841263_0001_r_000000_0 is allowed to commit now
15/08/12 14:11:36 INFO output.FileOutputCommitter: Saved output of task 'attempt_local858841263_0001_r_000000_0' to hdfs://localhost:9000/tmp/covar/mean-output/_temporary/0/task_local858841263_0001_r_000000
15/08/12 14:11:36 INFO mapred.LocalJobRunner: reduce &gt; reduce
15/08/12 14:11:36 INFO mapred.Task: Task 'attempt_local858841263_0001_r_000000_0' done.
15/08/12 14:11:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local858841263_0001_r_000000_0
15/08/12 14:11:36 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/12 14:11:37 INFO mapreduce.Job:  map 100% reduce 100%
15/08/12 14:11:37 INFO mapreduce.Job: Job job_local858841263_0001 completed successfully
15/08/12 14:11:37 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=409076
		FILE: Number of bytes written=1120646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=697122
		HDFS: Number of bytes written=44
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=230800
		Map output materialized bytes=185910
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=185910
		Reduce input records=25
		Reduce output records=1
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=203
		Total committed heap usage (bytes)=861929472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=348337
	File Output Format Counters 
		Bytes Written=44
&lt;/STDERR&gt;
EXITVAL: 0
./computeCovariance.sh /testout/covar/mediumtesthib.hib /tmp/covar
&lt;STDOUT&gt;
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/computeCovarianceTestDriver.jar /testout/covar/mediumtesthib.hib /tmp/covar
Running compute covariance.
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 348336
&lt;/STDOUT&gt;
&lt;STDERR&gt;
15/08/12 14:11:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/12 14:11:39 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
15/08/12 14:11:39 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/12 14:11:39 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/12 14:11:40 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/12 14:11:40 INFO input.FileInputFormat: Total input paths to process : 1
15/08/12 14:11:40 INFO mapreduce.JobSubmitter: number of splits:1
15/08/12 14:11:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1054280259_0001
15/08/12 14:11:40 INFO mapred.LocalDistributedCacheManager: Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403100593/part-r-00000 &lt;- /Users/zverham/Documents/School/4thYear/Research/hipi-covariance-update/hipi/examples/testSuite/part-r-00000
15/08/12 14:11:40 INFO mapred.LocalDistributedCacheManager: Localized hdfs://localhost:9000/tmp/covar/mean-output/part-r-00000 as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1439403100593/part-r-00000
15/08/12 14:11:40 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/12 14:11:40 INFO mapreduce.Job: Running job: job_local1054280259_0001
15/08/12 14:11:40 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/12 14:11:40 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/12 14:11:40 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/12 14:11:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1054280259_0001_m_000000_0
15/08/12 14:11:40 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/12 14:11:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/12 14:11:40 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/testout/covar/mediumtesthib.hib.dat:0+348337
15/08/12 14:11:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/12 14:11:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/12 14:11:40 INFO mapred.MapTask: soft limit at 83886080
15/08/12 14:11:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/12 14:11:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/12 14:11:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java(56850,0x119687000) malloc: *** mach_vm_map(size=973358629015654400) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCV Error: Insufficient memory (Failed to allocate 973358629015653878 bytes) in OutOfMemoryError, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/alloc.cpp, line 52
OpenCV Error: Assertion failed (u != 0) in create, file /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp, line 411
15/08/12 14:11:41 INFO mapred.MapTask: Starting flush of map output
15/08/12 14:11:41 INFO compress.CodecPool: Got brand-new compressor [.deflate]
15/08/12 14:11:41 INFO mapred.LocalJobRunner: map task executor complete.
15/08/12 14:11:41 WARN mapred.LocalJobRunner: job_local1054280259_0001
java.lang.Exception: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.RuntimeException: /Users/saudet/projects/bytedeco/javacpp-presets/opencv/cppbuild/macosx-x86_64/opencv-3.0.0/modules/core/src/matrix.cpp:411: error: (-215) u != 0 in function create

	at org.bytedeco.javacpp.opencv_core$Mat.allocate(Native Method)
	at org.bytedeco.javacpp.opencv_core$Mat.&lt;init&gt;(opencv_core.java:13840)
	at org.hipi.opencv.OpenCVMatWritable.readFields(OpenCVMatWritable.java:109)
	at org.hipi.examples.covar.CovarianceMapper.setup(CovarianceMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15/08/12 14:11:41 INFO mapreduce.Job: Job job_local1054280259_0001 running in uber mode : false
15/08/12 14:11:41 INFO mapreduce.Job:  map 0% reduce 0%
15/08/12 14:11:41 INFO mapreduce.Job: Job job_local1054280259_0001 failed with state FAILED due to: NA
15/08/12 14:11:41 INFO mapreduce.Job: Counters: 0
&lt;/STDERR&gt;
EXITVAL: 1
</pre>
</span>
</div>
<div id="tab3" class="tab">
<h2>Standard error</h2>
<span class="code">
<pre>log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
</pre>
</span>
</div>
</div>
<div id="footer">
<p>
<div>
<label class="hidden" id="label-for-line-wrapping-toggle" for="line-wrapping-toggle">Wrap lines
<input id="line-wrapping-toggle" type="checkbox" autocomplete="off"/>
</label>
</div>Generated by 
<a href="http://www.gradle.org">Gradle 2.4</a> at Aug 12, 2015 2:11:41 PM</p>
</div>
</div>
</body>
</html>
