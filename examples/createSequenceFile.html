<!DOCTYPE html">
<html>
  <head>
    <meta name="Description" content="Hadoop Image Processing Interface example for creating a HIB from a set of ,potentially Flickr, image URLs in a distributed manner." />
    <meta charset="UTF-8">
    <link rel="stylesheet" type="text/css" href="../include/main.css" />
    <link rel="stylesheet" type="text/css" href="../include/javasyntax.css" />
    <title>HIPI - Hadoop Image Processing Interface :: CreateSequenceFile Example</title>

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-23539446-1']);
      _gaq.push(['_trackPageview']);
  
  (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
  
    </script>
  
  </head>
  
  <body>
    <div class="header">
      <h1>HIPI - Hadoop Image Processing Framework</h1>
    </div>
    <div class="navigation_menu">
      <ul>
	<li><a href="../index.html">Introduction</a></li>
	<li><a href="../gettingstarted.html">Getting Started</a></li>
	<li><a href="../documentation.html">Documentation</a></li>
	<li><a href="../examples.html">Examples</a></li>
	<li><a href="../downloads.html">Downloads</a></li>
	<li><a href="../about.html">About</a></li>
      </ul>
    </div>
    
    <!-- Begin Content -->
    <div class="content">
      
      <h2>CreateSequenceFile</h2>
      <div class="section">
	
	JpegFromHib is an example program that
          creates a <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/io/SequenceFile.html">SequenceFile</a> from an input <a href="../doc/api/hipi/imagebundle/HipiImageBundle.html">HipiImageBundle</a> (HIB).
	
	<h3>Compiling the Example</h3>
	
	Before you can compile this (or any other example) you must
	configure the compiling script so that it knows where your
	Hadoop installation resides. Open up the build.xml file in the
	root directory of your HIPI installation. At the top of this
	file are three important properties named
	<strong>hadoop.home</strong>,
	<strong>hadoop.version</strong>,
    and <strong>hadoop.classpath</strong>. Fill in the value attributes
	of these three properties with the location of your Hadoop
	installation and your Hadoop version. For instance, if you
	downloaded Hadoop 2.5.1 and unpacked it to
	/opt/hadoop-2.5.1/share/hadoop, then you would have the following
	build.xml file:
	<pre id="Current">
  &#60;project basedir="." default="all"&#62;
	  
  &#60;target name="setup"&#62;
    &#60;property name="hadoop.version" value="2.5.1" /&#62;
    &#60;property name="hadoop.home" value="/opt/hadoop-${hadoop.version}/share/hadoop" /&#62;
    &#60;property name="hadoop.classpath" value="${hadoop.home}/common/hadoop-common-${hadoop.version}.jar:
    ${hadoop.home}/mapreduce/hadoop-mapreduce-client-core-${hadoop.version}.jar:
    ${hadoop.home}/common/lib/commons-cli-1.2.jar:${hadoop.home}/hdfs/hadoop-hdfs-${hadoop.version}.jar:
    ${hadoop.home}/common/hadoop-nfs-${hadoop.version}.jar" /&#62;
  ...
          </pre>
          
    <div class="important">Important Note:</div> Hadoop 2.5.1 requires five jars on its classpath (hadoop-common, hadoop-mapreduce-client-core, commons-cli, hadoop-hdfs, and hadoop-nfs). Ensure that these jar files are referenced in the hadoop.classpath property. </br></br>
	  
	  You can compile this example by executing the following
	  command in the root directory where you unpacked HIPI:
	  <pre id="Current">
            $> ant createsequencefile
      </pre>
	    	    
	    <div class="important">Important Note:</div> You must be
	    using Java JDK version 1.8 in order to ensure that HIPI
	    will compile correctly. Although earlier versions
	    <em>may</em> work, we have not fully tested them.
	    
	    <h3>Running the Example</h3> 
	    
	    We have provided a script in the <tt>examples</tt>
	    directory of the HIPI installation that will automatically
	    compile the createsequencefile program, upload the resulting jar
	    to the Hadoop Distributed Filesystem (HDFS), and run the
	    createsequencefile job. <br /><br />

	    The createsequencefile program takes two command line
	    parameters, which you can specify directly to the
	    <tt>runCreateSequenceFile.sh</tt> script. The first parameter is
	    the HDFS path to the HIB being referenced. The second parameter is the HDFS path to the output
	    directory that will be created once the program has
	    finished. The resulting SequenceFile will be stored in this directory. For example:
	    <pre id="Current">
            $> ./runCreateSequenceFile.sh /hdfs/path/to/input.hib /hdfs/path/to/outputDirectory
	    </pre>
      </div>
      
      <h2>Understanding CreateSequcenceFile</h2>
      <div class="section">
          <h3>SequenceFileMapper</h3>
          <h3>Reducer</h3>
          The reducer in this example is trivial, since there is no consolidation required for the SequenceFile created by the mapper step.
            This example makes use of Hadoop's base
            <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/mapreduce/Reducer.html">Reducer</a> class - a reducer is not implemented by this example.
      </div>
    </div>
    <!-- End Content -->
  </body>
</html>
