<!DOCTYPE html">
<html>
  <head>
    <meta name="Description" content="Hadoop Image Processing Interface example for creating a SequenceFile from a HipiImageBundle." />
    <meta charset="UTF-8">
    <link rel="stylesheet" type="text/css" href="../include/main.css" />
    <link rel="stylesheet" type="text/css" href="../include/javasyntax.css" />
    <title>HIPI - Hadoop Image Processing Interface :: CreateSequenceFile Example</title>

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-23539446-1']);
      _gaq.push(['_trackPageview']);
  
  (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
  
    </script>
  
  </head>
  
  <body>
    <div class="header">
      <h1>HIPI - Hadoop Image Processing Framework</h1>
    </div>
    <div class="navigation_menu">
      <ul>
	<li><a href="../index.html">Introduction</a></li>
	<li><a href="../gettingstarted.html">Getting Started</a></li>
	<li><a href="../documentation.html">Documentation</a></li>
	<li><a href="../examples.html">Examples</a></li>
	<li><a href="../downloads.html">Downloads</a></li>
	<li><a href="../about.html">About</a></li>
      </ul>
    </div>
    
    <!-- Begin Content -->
    <div class="content">
      
      <h2>CreateSequenceFile</h2>
      <div class="section">
	
	JpegFromHib is an example program that
          creates a <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/io/SequenceFile.html">SequenceFile</a> from an input <a href="../doc/api/hipi/imagebundle/HipiImageBundle.html">HipiImageBundle</a> (HIB).
	
	<h3>Compiling the Example</h3>
	
	Before you can compile this (or any other example) you must
	configure the compiling script so that it knows where your
	Hadoop installation resides. Open up the build.xml file in the
	root directory of your HIPI installation. At the top of this
	file are three important properties named
	<strong>hadoop.home</strong>,
	<strong>hadoop.version</strong>,
    and <strong>hadoop.classpath</strong>. Fill in the value attributes
	of these three properties with the location of your Hadoop
	installation and your Hadoop version. For instance, if you
	downloaded Hadoop 2.5.1 and unpacked it to
	/opt/hadoop-2.5.1/share/hadoop, then you would have the following
	build.xml file:
	<pre id="Current">
  &#60;project basedir="." default="all"&#62;
	  
  &#60;target name="setup"&#62;
    &#60;property name="hadoop.version" value="2.5.1" /&#62;
    &#60;property name="hadoop.home" value="/opt/hadoop-${hadoop.version}/share/hadoop" /&#62;
    &#60;property name="hadoop.classpath" value="${hadoop.home}/common/hadoop-common-${hadoop.version}.jar:
    ${hadoop.home}/mapreduce/hadoop-mapreduce-client-core-${hadoop.version}.jar:
    ${hadoop.home}/common/lib/commons-cli-1.2.jar:${hadoop.home}/hdfs/hadoop-hdfs-${hadoop.version}.jar:
    ${hadoop.home}/common/hadoop-nfs-${hadoop.version}.jar" /&#62;
  ...
          </pre>
          
    <div class="important">Important Note:</div> Hadoop 2.5.1 requires five jars on its classpath (hadoop-common, hadoop-mapreduce-client-core, commons-cli, hadoop-hdfs, and hadoop-nfs). Ensure that these jar files are referenced in the hadoop.classpath property. </br></br>
	  
	  You can compile this example by executing the following
	  command in the root directory where you unpacked HIPI:
	  <pre id="Current">
            $> ant createsequencefile
      </pre>
	    	    
	    <div class="important">Important Note:</div> You must be
	    using Java JDK version 1.8 in order to ensure that HIPI
	    will compile correctly. Although earlier versions
	    <em>may</em> work, we have not fully tested them.
	    
	    <h3>Running the Example</h3> 
	    
	    We have provided a script in the <tt>examples</tt>
	    directory of the HIPI installation that will automatically
	    compile the createsequencefile program, upload the resulting jar
	    to the Hadoop Distributed Filesystem (HDFS), and run the
	    createsequencefile job. <br /><br />

	    The createsequencefile program takes two command line
	    parameters, which you can specify directly to the
	    <tt>runCreateSequenceFile.sh</tt> script. The first parameter is
	    the HDFS path to the HIB being referenced. The second parameter is the HDFS path to the output
	    directory that will be created once the program has
	    finished. The resulting SequenceFile will be stored in this directory. For example:
	    <pre id="Current">
            $> ./runCreateSequenceFile.sh /hdfs/path/to/input.hib /hdfs/path/to/outputDirectory
	    </pre>
      </div>
      
      <h2>Understanding CreateSequcenceFile</h2>
      <div class="section">
          <h3>Job Configuration</h3>
            In CreateSequenceFile's run() method, many of the Hadoop
            <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/mapreduce/Job.html">Job</a>'s
            initial parameters are set. In particular, CreateSequenceFile contains the following line:
            <pre>
              job.setOutputFormatClass(SequenceFileOutputFormat.class);
            </pre>
            The <a class="external_link" class="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat.html">SequenceFileOutputFormat</a>
            class is provided by Hadoop and will generate an output which is structured as a Hadoop 
            <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/io/SequenceFile.html">SequenceFile</a>.
            <br/><br/><br/>
            Another important parameter being set ensures that the Job knows how to interpret its input:
            <pre>
              job.setInputFormatClass(ImageBundleInputFormat.class);
            </pre>
            The <a href="../doc/api/hipi/imagebundle/mapreduce/ImageBundleInputFormat.html">ImageBundleInputFormat</a> class ensures that the Job
            understands the formatting of the input and how to interact with it.
          <h3>SequenceFileMapper</h3>
          Here is the complete code from the SequenceFileMapper's map method:
          <pre>
            @Override
            public void map(ImageHeader key, FloatImage value, Context context) throws IOException,
                InterruptedException {
              if (value != null) {
                ImageEncoder encoder = JPEGImageUtil.getInstance();
                ByteArrayOutputStream os = new ByteArrayOutputStream();
                encoder.encodeImage(value, key, os);
                os.close();
                byte[] val = os.toByteArray();
                long sig = 0 << 2 | ImageType.JPEG_IMAGE.toValue();
                context.write(new LongWritable(sig), new BytesWritable(val));
              }
            }
          </pre>
          This accepts an <a href="../doc/api/hipi/image/ImageHeader.html">ImageHeader</a> and <a href="../doc/api/hipi/image/FloatImage.html">FloatImage</a>
          as a key/value pair. It then makes use of HIPI's <a href="../doc/api/hipi/image/io/JPEGImageUtil.html">JPEGImageUtil</a> class to create an
          <a href="../doc/api/hipi/image/io/ImageEncoder.html">ImageEncoder</a> object. This encoder encodes the image's key/value pair to a
          <a class="external_link" href="http://docs.oracle.com/javase/7/docs/api/java/io/ByteArrayOutputStream.html">ByteArrayOutputStream</a>, which
          can be subsequently read and passed into a 
          <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/io/BytesWritable.html">BytesWritable</a> object.
        
          <h3>Reducer</h3>
          The reducer in this example is trivial, since there is no consolidation required for the SequenceFile created by the mapper step.
            This example makes use of Hadoop's base
            <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/mapreduce/Reducer.html">Reducer</a> class - a reducer is not implemented by this example.
      </div>
    </div>
    <!-- End Content -->
  </body>
</html>
