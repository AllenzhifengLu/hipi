<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="org.hipi.tools.test.HibImportTests" tests="2" skipped="0" failures="0" errors="0" timestamp="2015-08-10T15:01:15" hostname="Zacks-MacBook-Pro.local" time="29.232">
  <properties/>
  <testcase name="testHibImport" classname="org.hipi.tools.test.HibImportTests" time="6.904"/>
  <testcase name="testHibImportAndCull" classname="org.hipi.tools.test.HibImportTests" time="22.328"/>
  <system-out><![CDATA[hadoop fs -rm -r -f testout
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -rm -r -f testout
Deleted testout
</STDOUT>
<STDERR>
15/08/10 11:00:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/10 11:00:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p testout
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p testout
</STDOUT>
<STDERR>
15/08/10 11:00:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p testout/downloader_src
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p testout/downloader_src
</STDOUT>
<STDERR>
15/08/10 11:01:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p testout/flickr_src
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p testout/flickr_src
</STDOUT>
<STDERR>
15/08/10 11:01:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -mkdir -p testout/flickr_bz2_src
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -mkdir -p testout/flickr_bz2_src
</STDOUT>
<STDERR>
15/08/10 11:01:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/downloader-images.txt testout/downloader_src/downloader-images.txt
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/downloader-images.txt testout/downloader_src/downloader-images.txt
</STDOUT>
<STDERR>
15/08/10 11:01:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-0 testout/flickr_src/yfcc100m_dataset-100-temp-0
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-0 testout/flickr_src/yfcc100m_dataset-100-temp-0
</STDOUT>
<STDERR>
15/08/10 11:01:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-1 testout/flickr_src/yfcc100m_dataset-100-temp-1
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-1 testout/flickr_src/yfcc100m_dataset-100-temp-1
</STDOUT>
<STDERR>
15/08/10 11:01:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-0.bz2 testout/flickr_bz2_src/yfcc100m_dataset-100-temp-0.bz2
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-0.bz2 testout/flickr_bz2_src/yfcc100m_dataset-100-temp-0.bz2
</STDOUT>
<STDERR>
15/08/10 11:01:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
hadoop fs -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-1.bz2 testout/flickr_bz2_src/yfcc100m_dataset-100-temp-1.bz2
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyFromLocal ../../testdata/yfcc100m_dataset-100-temp-1.bz2 testout/flickr_bz2_src/yfcc100m_dataset-100-temp-1.bz2
</STDOUT>
<STDERR>
15/08/10 11:01:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
../hibImport.sh -f ../../testdata/jpeg-and-png testout/import.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ../hibImport/build/libs/hibImport.jar -f ../../testdata/jpeg-and-png testout/import.hib
Input image directory: ../../testdata/jpeg-and-png
Output HIB: testout/import.hib
Overwrite HIB if it exists: true
HIPI: Using default blockSize of [134217728].
HIPI: Using default replication factor of [1].
 ** added: 01.jpg
 ** added: 01.png
 ** added: canon-ixus.jpg
Created: testout/import.hib and testout/import.hib.dat
</STDOUT>
<STDERR>
15/08/10 11:01:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
../hibInfo.sh testout/import.hib 1 --extract /tmp/test.jpg
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ../hibInfo/build/libs/hibInfo.jar testout/import.hib 1 --extract /tmp/test.jpg
Input HIB: testout/import.hib
Display meta data: false
Display EXIF data: false
Image index: 1
Extract image path: /tmp/test.jpg
Meta data key: none
   1024 x 767
   format: 2
Using image encoder: com.twelvemonkeys.imageio.plugins.jpeg.JPEGImageWriter@6aa3a905
Wrote [/tmp/test.jpg]
</STDOUT>
<STDERR>
15/08/10 11:01:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
compare -metric PSNR ../../testdata/jpeg-and-png/01.png /tmp/test.jpg /tmp/psnr.png
PSNR: 35.6288
../hibImport.sh -f ../../testdata/jpeg-rgb testout/import.hib
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ../hibImport/build/libs/hibImport.jar -f ../../testdata/jpeg-rgb testout/import.hib
Input image directory: ../../testdata/jpeg-rgb
Output HIB: testout/import.hib
Overwrite HIB if it exists: true
HIPI: Using default blockSize of [134217728].
HIPI: Using default replication factor of [1].
 ** added: 01.jpeg
 ** added: 02.jpg
 ** added: 03.jpg
 ** added: 04.jpg
 ** added: 05.jpg
 ** added: canon-ixus.jpg
 ** added: cat.jpg
Created: testout/import.hib and testout/import.hib.dat
</STDOUT>
<STDERR>
15/08/10 11:01:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
../hibInfo.sh testout/import.hib 4 --extract /tmp/test.png
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ../hibInfo/build/libs/hibInfo.jar testout/import.hib 4 --extract /tmp/test.png
Input HIB: testout/import.hib
Display meta data: false
Display EXIF data: false
Image index: 4
Extract image path: /tmp/test.png
Meta data key: none
   3456 x 2304
   format: 1
Using image encoder: com.sun.imageio.plugins.png.PNGImageWriter@604c5de8
Wrote [/tmp/test.png]
</STDOUT>
<STDERR>
15/08/10 11:01:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</STDERR>
EXITVAL: 0
compare -metric PSNR ../../testdata/jpeg-rgb/05.jpg /tmp/test.png /tmp/psnr.png
PSNR: 52.3468
../runTool.sh ./build/libs/dumpHib.jar testout/import.hib testout/import_dump
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar ./build/libs/dumpHib.jar testout/import.hib testout/import_dump
Spawned 1map tasks
HibRecordReader#initialize: Input split starts at byte offset 0 and ends at byte offset 14700521
Inside cull with header: ImageHeader: (1 1) 3456 x 2304 x 3 meta: {"source":"..\/..\/testdata\/jpeg-rgb\/01.JPEG"}
CULLED (image width filter)
Inside cull with header: ImageHeader: (1 1) 3072 x 2304 x 3 meta: {"source":"..\/..\/testdata\/jpeg-rgb\/02.JPG"}
NOT CULLED
Inside cull with header: ImageHeader: (1 1) 2592 x 1944 x 3 meta: {"source":"..\/..\/testdata\/jpeg-rgb\/03.jpg"}
NOT CULLED
Inside cull with header: ImageHeader: (1 1) 3072 x 2304 x 3 meta: {"source":"..\/..\/testdata\/jpeg-rgb\/04.jpg"}
NOT CULLED
Inside cull with header: ImageHeader: (1 1) 3456 x 2304 x 3 meta: {"source":"..\/..\/testdata\/jpeg-rgb\/05.jpg"}
CULLED (image width filter)
Inside cull with header: ImageHeader: (1 1) 640 x 480 x 3 meta: {"source":"..\/..\/testdata\/jpeg-rgb\/canon-ixus.jpg"}
CULLED (filename filter)
Inside cull with header: ImageHeader: (1 1) 500 x 375 x 3 meta: {"source":"..\/..\/testdata\/jpeg-rgb\/cat.jpg"}
NOT CULLED
</STDOUT>
<STDERR>
15/08/10 11:01:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/10 11:01:37 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/08/10 11:01:37 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/08/10 11:01:37 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/08/10 11:01:37 INFO input.FileInputFormat: Total input paths to process : 1
15/08/10 11:01:37 INFO mapreduce.JobSubmitter: number of splits:1
15/08/10 11:01:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1446084341_0001
15/08/10 11:01:38 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/08/10 11:01:38 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/08/10 11:01:38 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/08/10 11:01:38 INFO mapreduce.Job: Running job: job_local1446084341_0001
15/08/10 11:01:38 INFO mapred.LocalJobRunner: Waiting for map tasks
15/08/10 11:01:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1446084341_0001_m_000000_0
15/08/10 11:01:38 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/10 11:01:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/10 11:01:38 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/zverham/testout/import.hib.dat:0+14700522
15/08/10 11:01:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/08/10 11:01:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/08/10 11:01:38 INFO mapred.MapTask: soft limit at 83886080
15/08/10 11:01:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/08/10 11:01:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/08/10 11:01:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/08/10 11:01:39 INFO mapreduce.Job: Job job_local1446084341_0001 running in uber mode : false
15/08/10 11:01:39 INFO mapreduce.Job:  map 0% reduce 0%
15/08/10 11:01:41 INFO mapred.LocalJobRunner: 
15/08/10 11:01:41 INFO mapred.MapTask: Starting flush of map output
15/08/10 11:01:41 INFO mapred.MapTask: Spilling map output
15/08/10 11:01:41 INFO mapred.MapTask: bufstart = 0; bufend = 263; bufvoid = 104857600
15/08/10 11:01:41 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
15/08/10 11:01:41 INFO mapred.MapTask: Finished spill 0
15/08/10 11:01:41 INFO mapred.Task: Task:attempt_local1446084341_0001_m_000000_0 is done. And is in the process of committing
15/08/10 11:01:41 INFO mapred.LocalJobRunner: map
15/08/10 11:01:41 INFO mapred.Task: Task 'attempt_local1446084341_0001_m_000000_0' done.
15/08/10 11:01:41 INFO mapred.LocalJobRunner: Finishing task: attempt_local1446084341_0001_m_000000_0
15/08/10 11:01:41 INFO mapred.LocalJobRunner: map task executor complete.
15/08/10 11:01:41 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/08/10 11:01:41 INFO mapred.LocalJobRunner: Starting task: attempt_local1446084341_0001_r_000000_0
15/08/10 11:01:41 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/08/10 11:01:41 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/08/10 11:01:41 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@25d8828b
15/08/10 11:01:41 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/08/10 11:01:41 INFO reduce.EventFetcher: attempt_local1446084341_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/08/10 11:01:41 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1446084341_0001_m_000000_0 decomp: 273 len: 277 to MEMORY
15/08/10 11:01:41 INFO reduce.InMemoryMapOutput: Read 273 bytes from map-output for attempt_local1446084341_0001_m_000000_0
15/08/10 11:01:41 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 273, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->273
15/08/10 11:01:41 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/08/10 11:01:41 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/10 11:01:41 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/08/10 11:01:41 INFO mapreduce.Job:  map 100% reduce 0%
15/08/10 11:01:41 INFO mapred.Merger: Merging 1 sorted segments
15/08/10 11:01:41 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 267 bytes
15/08/10 11:01:41 INFO reduce.MergeManagerImpl: Merged 1 segments, 273 bytes to disk to satisfy reduce memory limit
15/08/10 11:01:41 INFO reduce.MergeManagerImpl: Merging 1 files, 277 bytes from disk
15/08/10 11:01:41 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/08/10 11:01:41 INFO mapred.Merger: Merging 1 sorted segments
15/08/10 11:01:41 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 267 bytes
15/08/10 11:01:41 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/10 11:01:41 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/08/10 11:01:41 INFO mapred.Task: Task:attempt_local1446084341_0001_r_000000_0 is done. And is in the process of committing
15/08/10 11:01:41 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/08/10 11:01:41 INFO mapred.Task: Task attempt_local1446084341_0001_r_000000_0 is allowed to commit now
15/08/10 11:01:41 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1446084341_0001_r_000000_0' to hdfs://localhost:9000/user/zverham/testout/import_dump/_temporary/0/task_local1446084341_0001_r_000000
15/08/10 11:01:41 INFO mapred.LocalJobRunner: reduce > reduce
15/08/10 11:01:41 INFO mapred.Task: Task 'attempt_local1446084341_0001_r_000000_0' done.
15/08/10 11:01:41 INFO mapred.LocalJobRunner: Finishing task: attempt_local1446084341_0001_r_000000_0
15/08/10 11:01:41 INFO mapred.LocalJobRunner: reduce task executor complete.
15/08/10 11:01:42 INFO mapreduce.Job:  map 100% reduce 100%
15/08/10 11:01:42 INFO mapreduce.Job: Job job_local1446084341_0001 completed successfully
15/08/10 11:01:42 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=22190
		FILE: Number of bytes written=549899
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=29401204
		HDFS: Number of bytes written=255
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=263
		Map output materialized bytes=277
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=277
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=265
		Total committed heap usage (bytes)=956825600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14700522
	File Output Format Counters 
		Bytes Written=255
</STDERR>
EXITVAL: 0
hadoop fs -copyToLocal testout/import_dump
<STDOUT>
/usr/local/Cellar/hadoop/2.6.0/libexec/etc/hadoop:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/hdfs/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/yarn/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/lib/*:/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/mapreduce/*:/contrib/capacity-scheduler/*.jar
/Library/Java/JavaVirtualMachines/jdk1.8.0_51.jdk/Contents/Home/bin/java -Xmx1000m -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc= -Dhadoop.log.dir=/usr/local/Cellar/hadoop/2.6.0/libexec/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/local/Cellar/hadoop/2.6.0/libexec -Dhadoop.id.str=zverham -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx512m -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.FsShell -copyToLocal testout/import_dump
</STDOUT>
<STDERR>
15/08/10 11:01:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
copyToLocal: `import_dump/_SUCCESS': File exists
copyToLocal: `import_dump/part-r-00000': File exists
</STDERR>
EXITVAL: 1
]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
