<!DOCTYPE html>
<html>
  <head>
    <meta name="Description" content="HIPI - Hadoop Image Processing Interface getting started page tells you what you need to know to start using HIPI on Hadoop MapReduce." />
    <meta charset="UTF-8">
    
    <link rel="stylesheet" type="text/css" href="include/main.css" />
    <link rel="stylesheet" type="text/css" href="include/javasyntax.css" />
    <title>HIPI - Hadoop Image Processing Interface :: Getting Started</title>

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-23539446-1']);
      _gaq.push(['_trackPageview']);
  
  (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
  
    </script>
  
  </head>
  
  <body>
    <div class="header">
      <h1>HIPI - Hadoop Image Processing Framework</h1>
    </div>
    <div class="navigation_menu">
      <ul>
	<li><a href="index.html">Introduction</a></li>
	<li><a href="gettingstarted.html">Getting Started</a></li>
	<li><a href="documentation.html">Documentation</a></li>
	<li><a href="examples.html">Examples</a></li>
	<li><a href="downloads.html">Downloads</a></li>
	<li><a href="about.html">About</a></li>
      </ul>
    </div>
    
    <!-- Begin Content -->
    <div class="content">
      
      <h2>Setting up the Hadoop Framework</h2>
      <h3>Getting Hadoop</h3>
      <div class="section">
	You must first download the Hadoop MapReduce framework from <a
	class="external_link"
	href="http://hadoop.apache.org/#Download+Hadoop">Apache's
	website</a>. <br /><br />
      
	<h3>Configuring Hadoop</h3> 

	Please refer to the Hadoop documentation pages listed below
	for specifics on how to configure your installation:
	<ul>
	  <li>For the most current Hadoop version use this <a class="external_link" href="http://wiki.apache.org/hadoop/QuickStart">Quickstart Guide</a></li>
	  <li>To setup a single node on your computer, check out <a class="external_link" href="http://hadoop.apache.org/docs/r2.5.1/hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a></li>
	</ul>

	It is a good idea to add the bin directory to your PATH
	environment variable to avoid having to type the absolute path
	to Hadoop for every command. For example, if you downloaded
	and unpacked Hadoop to
	/opt/hadoop/, then you would add the following to
	your .bashrc (or equivalent):
	<pre id="Current">
  export PATH=$PATH:/opt/hadoop/bin
	</pre>	
          
    A package manager may simplify the installation and configuration process (<a class="external_link" href="http://brew.sh">Homebrew</a> for OSX). <br /><br />
    Note that HIPI makes use of <a class="external_link" href="http://ant.apache.org/">Apache Ant</a> for code compilation. 
      </div>

      <h2>Downloading HIPI</h2>
      <div class="section">
        The source code for HIPI can be found on
        <a class="external_link" href="https://github.com/uvagfx/hipi">github</a>, 
        or can be downloaded as a compiled jar from our
        <a href="downloads.html">downloads</a> page.
        <br /><br	/>

        In order to use the HIPI API, you must add the jar file you
        downloaded above to the build path. The way you achieve this
        varies from setup to setup. In Eclipse you will have to add
        the jar file to the Java Build Path in your Project
        Settings. In ANT you will specify the jar file in the
        classpath attribute of the Javac Task along with any other
        libraries you may need (such as Hadoop).<br /><br />

        You can find sample ANT build tasks in HIPI's root build.xml file. <br /><br />

        Check out the <a href="examples.html">examples</a> page for
        information on creating programs that utilize HIPI.<br /><br />
      </div>

      <h2>Checking What You Have</h2>
      <div class="section">
		  The "Getting Started" tutorial will assume that you have Hadoop and HIPI
		  installed locally.
		  Please reach this point before proceeding.<br /><br />

		  A good way to ensure your system is configured properly
		  is to build HIPI library/examples/tool on your own computer. Try to run
		  "ant" at the root directory. You probably need to change hadoop.classpath, hadoop.version,
		  and hadoop.home in build.xml to build HIPI successfully.<br /><br />

		  To confirm that everything has compiled properly after running the ant command above, run:
		<pre id="Classes">
  hadoop jar tool/hibimport.jar ~/Pictures picture.hib
        </pre>
		Where ~/Pictures represents a directory that contains images. This command will
		create two files on the <a class="external_link" href="http://hadoop.apache.org/docs/r2.5.1/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">
    Hadoop Distributed Filesystem (HDFS) </a>: picture.hib and picture.hib.dat. To view them, run the command: <tt>hadoop dfs -ls</tt><br /><br />
      </div>
    <h2>Writing Your First HIPI Program (Average Color of Images)</h2>
        <div class="section">
            Although HIPI can easily be integrated into
		  your current Hadoop project, this tutorial will work through an example program which will compute the average color of a set of images.<br /></br />
	  <h3>Configuring Ant</h3>

		  Open your root build.xml file (./build.xml), and add a new target:
		  <pre id="Classes">
  &lt;target name="firstprog"&gt;
    &lt;antcall target="compile"&gt;
      &lt;param name="srcdir" value="firstprog" /&gt;
      &lt;param name="jarfilename" value="firstprog.jar" /&gt;
      &lt;param name="jardir" value="firstprog" /&gt;
      &lt;param name="mainclass" value="FirstProgram" /&gt;
    &lt;/antcall&gt;
  &lt;/target&gt;
		  </pre>
		  You will also need to create the directory ./firstprog, and create the new
		  Java file ./firstprog/FirstProgram.java.<br /><br />

		  FirstProgram.java can be as simple as:
		  <pre id="Classes">
  <font id="Public">public</font> <font id="Class">class</font> FirstProgram <font id="Extends">extends</font> Configured <font id="Implements">implements</font> Tool {
	<font id="Public">public</font> <font id="Static">static</font> <font id="Void">void</font> main(String[] args) <font id="Throws">throws</font> Exception {
        System.out.println("Hello HIPI!");
        System.exit(0);
    }
  }
		  </pre>

		  Try to build again as suggested in "Checking What you Have", if your code
		  builds, you should have firstprog.jar file in ./firstprog directory.
		  Congratulations! This is your *first* HIPI program.<br /><br />

	  <h3>Hadoop MapReduce</h3>

		  Hadoop's MapReduce mechanism makes it an extremely powerful cluster computing framework.
		  Hadoop's official <a href="http://hadoop.apache.org/docs/r2.5.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">MapReduce tutorial</a> provides a useful introduction to the MapReduce paradigm. 
		  After working through this tutorial, you should be able to create Mapper and Reducer classes for our
		  dummy program:
		  <pre id="Classes">
  <font id="Public">public</font> <font id="Class">class</font> FirstProgram <font id="Extends">extends</font> Configured <font id="Implements">implements</font> Tool {
    <font id="Public">public</font> <font id="Static">static</font> <font id="Class">class</font> MyMap <font id="Extends">extends</font> Mapper&lt;ImageHeader, FloatImage, IntWritable, FloatImage&gt; {
      <font id="Public">public</font> <font id="Void">void</font> map(ImageHeader key, FloatImage value, Context context)
        <font id="Throws">throws</font> IOException, InterruptedException {
      }
    }
    <font id="Public">public</font> <font id="Static">static</font> <font id="Class">class</font> MyReduce <font id="Extends">extends</font> Reducer&lt;IntWritable, FloatImage, IntWritable, FloatImage&gt; {
      <font id="Public">public</font> <font id="Void">void</font> reduce(IntWritable key, Iterable<FloatImage> values, Context context)
        <font id="Throws">throws</font> IOException, InterruptedException {
      }
    }

    <font id="Public">public</font> int run(String[] args) <font id="Throws">throws</font> Exception {
      Job job = Job.getInstance();
      job.setJarByClass(FirstProgram.class);
      job.setOutputKeyClass(IntWritable.class);
      job.setOutputValueClass(FloatImage.class);

      job.setMapperClass(MyMap.class);
      job.setCombinerClass(MyReduce.class);
      job.setReducerClass(MyReduce.class);

      String inputFileType = args[2];
      job.setOutputFormatClass(BinaryOutputFormat.class);

      FileInputFormat.setInputPaths(job, new Path(args[0]));
      FileOutputFormat.setOutputPath(job, new Path(args[1]));

      boolean success = job.waitForCompletion(true);
      return success ? 0 : 1;
    }

    <font id="Public">public</font> <font id="Static">static</font> <font id="Void">void</font> main(String[] args) <font id="Throws">throws</font> Exception {
      ToolRunner.run(new FirstProgram(), args);
      System.exit(0);
    }
  }
		  </pre>
		  This looks like alot of code, but most of it is setting up the Hadoop <a class="external_link" href="https://hadoop.apache.org/docs/r2.5.1/api/org/apache/hadoop/mapred/jobcontrol/Job.html">Job</a> and will look similar across all Hadoop programs you write. The core functionality of the code (the internals of your Mapper and Reducer classes) is still unimplemented.<br /><br />

		  Test to ensure your code works here by compiling it (run "ant firstprog" from the directory containing your build.xml file).<br /><br />

	  <h3>Computing Average Color</h3>
		  Let's begin adding some functionality to our program.
		  For this example, we will be computing the average color of images. Our mapper will compute the average color of a single image, and the reducer will sum up the average colors to compute the total average image color.<br /><br />

		  Here's our mapper:
		  <pre id="Classes">
    <font id="Public">public</font> <font id="Static">static</font> <font id="Class">class</font> MyMap <font id="Extends">extends</font> Mapper&lt;ImageHeader, FloatImage, IntWritable, FloatImage&gt; {
      <font id="Public">public</font> <font id="Void">void</font> map(ImageHeader key, FloatImage value, Context context)
        <font id="Throws">throws</font> IOException, InterruptedException {
        if (value != null && value.getWidth() > 1 && value.getHeight() > 1 && value.getBands() == 3) {
          FloatImage avg = new FloatImage(1, 1, 3);
          float[] avgData = avg.getData();
          float[] valData = value.getData();
          for (int i = 0; i < value.getWidth(); i++) {
            for (int j = 0; j < value.getHeight(); j++) {
              avgData[0] += valData[i * value.getHeight() * 3 + j * 3];
              avgData[1] += valData[i * value.getHeight() * 3 + j * 3 + 1];
              avgData[2] += valData[i * value.getHeight() * 3 + j * 3 + 2];
            }
          }
          avg.scale(1.0f / (value.getWidth() * value.getHeight()));
          context.write(new IntWritable(0), avg);
        }
      }
    }
	</pre>
		  This creates 1x1 FloatImage which is passed to the reducer:
		  <pre id="Classes">
    <font id="Public">public</font> <font id="Static">static</font> <font id="Class">class</font> MyReduce <font id="Extends">extends</font> Reducer&lt;IntWritable, FloatImage, IntWritable, FloatImage&gt; 
      <font id="Public">public</font> <font id="Void">void</font> reduce(IntWritable key, Iterable<FloatImage> values, Context context)
        <font id="Throws">throws</font> IOException, InterruptedException {
        FloatImage avg = new FloatImage(1, 1, 3);
        int total = 0;
        for (FloatImage val : values) {
          avg.add(val);
          total++;
        }
        if (total > 0) {
          avg.scale(1.0f / total);
          context.write(key, avg);
        }
      }
	</pre>
	Again, double-check and make sure your code compiles at this point. <br /><br />

	  <h3>Running Your First Program</h3>
	  <div class="section">
		  The compiled jar file should be in ./firstprog/firstprog.jar which can be run with the picture.hib file you created above:
		  <pre id="Classes">
  hadoop jar firstprog/firstprog.jar picture.hib .
		  </pre>
		  This will create a binary file which contains the average color of the images stored in picture.hib.<br /><br />

          This example provides a foretaste of how HIPI extends Hadoop so that it can handle image files
		  seamlessly. For further reference, the <a href="examples.html">examples</a> page contains more sophisticated usages of HIPI.<br /><br />
	  </div>
    </div>
    <!-- End Content -->
  </body>
</html>
  
